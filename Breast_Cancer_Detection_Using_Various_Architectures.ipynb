{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Breast Cancer Detection Using Various Architectures.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAWpWnXKmpmq",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "ec6f0092-1aa3-492f-c760-f131072e2f16"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-16ff26ec-ac14-424e-9a44-537fb06dff5c\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-16ff26ec-ac14-424e-9a44-537fb06dff5c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Brest Cancer Dataset.zip to Brest Cancer Dataset.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_QtQlw7nJlY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "bed08438-4d8d-440c-8b51-5e46d050b8bb"
      },
      "source": [
        "# importing required modules \n",
        "from zipfile import ZipFile \n",
        "  \n",
        "# specifying the zip file name \n",
        "file_name = \"Brest Cancer Dataset.zip\"\n",
        "  \n",
        "# opening the zip file in READ mode \n",
        "with ZipFile(file_name, 'r') as zip: \n",
        "    # printing all the contents of the zip file \n",
        "    zip.printdir() \n",
        "  \n",
        "    # extracting all the files \n",
        "    print('Extracting all the files now...') \n",
        "    zip.extractall() \n",
        "    print('Done!') \n",
        "    zip.close()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File Name                                             Modified             Size\n",
            "Brest Cancer Dataset.csv                       2019-07-09 23:53:20       125141\n",
            "Extracting all the files now...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVquczr_nz7_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "72c28db7-880c-4b34-93fa-ae5d7f2fbee5"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "plt.figure(figsize=(5,5))\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datetime import datetime as dt\n",
        "\n",
        "#-----------------------------------------------------\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#----------------------------------------------------\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "#----------------------------------------------------\n",
        "\n",
        "import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "#----------------------------------------------------"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdepvs6UomHR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "250a56db-9f13-47f1-8a40-f45ab039d4c3"
      },
      "source": [
        "df = pd.read_csv('Brest Cancer Dataset.csv')\n",
        "df.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83rKmQojpBJU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "f9cb282b-cbaf-4b10-b7e5-c28b8a9384e6"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>diagnosis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  radius_mean  ...  fractal_dimension_worst  diagnosis\n",
              "0    842302        17.99  ...                  0.11890          M\n",
              "1    842517        20.57  ...                  0.08902          M\n",
              "2  84300903        19.69  ...                  0.08758          M\n",
              "3  84348301        11.42  ...                  0.17300          M\n",
              "4  84358402        20.29  ...                  0.07678          M\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hx9fb7sTpNCE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "306fa50f-de8e-48d0-fc71-61fa9be3fd7c"
      },
      "source": [
        "df.drop(['id'], axis = 1, inplace = True)\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>diagnosis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   radius_mean  texture_mean  ...  fractal_dimension_worst  diagnosis\n",
              "0        17.99         10.38  ...                  0.11890          M\n",
              "1        20.57         17.77  ...                  0.08902          M\n",
              "2        19.69         21.25  ...                  0.08758          M\n",
              "3        11.42         20.38  ...                  0.17300          M\n",
              "4        20.29         14.34  ...                  0.07678          M\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbc051kupM-Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "bbc8b390-a019-49af-a97c-3223d9a4be3a"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>0.062798</td>\n",
              "      <td>0.405172</td>\n",
              "      <td>1.216853</td>\n",
              "      <td>2.866059</td>\n",
              "      <td>40.337079</td>\n",
              "      <td>0.007041</td>\n",
              "      <td>0.025478</td>\n",
              "      <td>0.031894</td>\n",
              "      <td>0.011796</td>\n",
              "      <td>0.020542</td>\n",
              "      <td>0.003795</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.277313</td>\n",
              "      <td>0.551648</td>\n",
              "      <td>2.021855</td>\n",
              "      <td>45.491006</td>\n",
              "      <td>0.003003</td>\n",
              "      <td>0.017908</td>\n",
              "      <td>0.030186</td>\n",
              "      <td>0.006170</td>\n",
              "      <td>0.008266</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>0.111500</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.757000</td>\n",
              "      <td>6.802000</td>\n",
              "      <td>0.001713</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007882</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>0.232400</td>\n",
              "      <td>0.833900</td>\n",
              "      <td>1.606000</td>\n",
              "      <td>17.850000</td>\n",
              "      <td>0.005169</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.015090</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>0.015160</td>\n",
              "      <td>0.002248</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.324200</td>\n",
              "      <td>1.108000</td>\n",
              "      <td>2.287000</td>\n",
              "      <td>24.530000</td>\n",
              "      <td>0.006380</td>\n",
              "      <td>0.020450</td>\n",
              "      <td>0.025890</td>\n",
              "      <td>0.010930</td>\n",
              "      <td>0.018730</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>0.478900</td>\n",
              "      <td>1.474000</td>\n",
              "      <td>3.357000</td>\n",
              "      <td>45.190000</td>\n",
              "      <td>0.008146</td>\n",
              "      <td>0.032450</td>\n",
              "      <td>0.042050</td>\n",
              "      <td>0.014710</td>\n",
              "      <td>0.023480</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097440</td>\n",
              "      <td>2.873000</td>\n",
              "      <td>4.885000</td>\n",
              "      <td>21.980000</td>\n",
              "      <td>542.200000</td>\n",
              "      <td>0.031130</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>0.396000</td>\n",
              "      <td>0.052790</td>\n",
              "      <td>0.078950</td>\n",
              "      <td>0.029840</td>\n",
              "      <td>36.040000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       radius_mean  texture_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "count   569.000000    569.000000  ...      569.000000               569.000000\n",
              "mean     14.127292     19.289649  ...        0.290076                 0.083946\n",
              "std       3.524049      4.301036  ...        0.061867                 0.018061\n",
              "min       6.981000      9.710000  ...        0.156500                 0.055040\n",
              "25%      11.700000     16.170000  ...        0.250400                 0.071460\n",
              "50%      13.370000     18.840000  ...        0.282200                 0.080040\n",
              "75%      15.780000     21.800000  ...        0.317900                 0.092080\n",
              "max      28.110000     39.280000  ...        0.663800                 0.207500\n",
              "\n",
              "[8 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ipq2QBLpLDc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "2bfae83f-c550-4f74-8e58-92aab2bcea84"
      },
      "source": [
        "# 1 \n",
        "concavity_mean = 1\n",
        "for i in df['concavity_mean']:\n",
        "  if i == 0:\n",
        "    concavity_mean += 1\n",
        "print(concavity_mean)\n",
        "\n",
        "# 2 \n",
        "concave_points_mean = 1\n",
        "for i in df['concave points_mean']:\n",
        "  if i == 0:\n",
        "    concave_points_mean += 1\n",
        "print(concave_points_mean)\n",
        "\n",
        "# 2\n",
        "symmetry_mean = 1\n",
        "for i in df['symmetry_mean']:\n",
        "  if i == 0:\n",
        "    symmetry_mean += 1\n",
        "print(symmetry_mean)\n",
        "\n",
        "#only 14 zeros out of 569 data points is considerable"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14\n",
            "14\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPBv1BrRq_cy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "outputId": "d87e5a3b-e979-4c00-feb9-bc151dc6333e"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 31 columns):\n",
            "radius_mean                569 non-null float64\n",
            "texture_mean               569 non-null float64\n",
            "perimeter_mean             569 non-null float64\n",
            "area_mean                  569 non-null float64\n",
            "smoothness_mean            569 non-null float64\n",
            "compactness_mean           569 non-null float64\n",
            "concavity_mean             569 non-null float64\n",
            "concave points_mean        569 non-null float64\n",
            "symmetry_mean              569 non-null float64\n",
            "fractal_dimension_mean     569 non-null float64\n",
            "radius_se                  569 non-null float64\n",
            "texture_se                 569 non-null float64\n",
            "perimeter_se               569 non-null float64\n",
            "area_se                    569 non-null float64\n",
            "smoothness_se              569 non-null float64\n",
            "compactness_se             569 non-null float64\n",
            "concavity_se               569 non-null float64\n",
            "concave points_se          569 non-null float64\n",
            "symmetry_se                569 non-null float64\n",
            "fractal_dimension_se       569 non-null float64\n",
            "radius_worst               569 non-null float64\n",
            "texture_worst              569 non-null float64\n",
            "perimeter_worst            569 non-null float64\n",
            "area_worst                 569 non-null float64\n",
            "smoothness_worst           569 non-null float64\n",
            "compactness_worst          569 non-null float64\n",
            "concavity_worst            569 non-null float64\n",
            "concave points_worst       569 non-null float64\n",
            "symmetry_worst             569 non-null float64\n",
            "fractal_dimension_worst    569 non-null float64\n",
            "diagnosis                  569 non-null object\n",
            "dtypes: float64(30), object(1)\n",
            "memory usage: 137.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5jwStGIsukX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "6dda5974-8aef-4f64-d24b-81746ba69d9f"
      },
      "source": [
        "df['diagnosis'].value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "B    357\n",
              "M    212\n",
              "Name: diagnosis, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l2IUlrjs7n-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "86a09c52-ec77-4d16-b8dd-fa91f8611d89"
      },
      "source": [
        "#Encoding Male and Female to 1 and 0\n",
        "df['diagnosis'] = df['diagnosis'].map({'M': 0, 'B': 1})\n",
        "df['diagnosis'].head(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    0\n",
              "Name: diagnosis, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsyyqmYlrCZ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e89b7a28-45cb-4de8-be03-7e02169b5bff"
      },
      "source": [
        "X = df.iloc[:, :-1].values\n",
        "Y = df.iloc[:, 30].values\n",
        "\n",
        "print(\"X: {}\".format(X.shape))\n",
        "print(\"Y: {}\".format(Y.shape))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X: (569, 30)\n",
            "Y: (569,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unjrl3U_rMls",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "58288e38-97a3-422d-a30e-8326b6bea25c"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, \n",
        "                                                    Y, \n",
        "                                                    test_size = 0.175,\n",
        "                                                    random_state = 0)\n",
        "\n",
        "print(\"X_train: {}\".format(X_train.shape))\n",
        "print(\"X_test: {}\".format(X_test.shape))\n",
        "print(\"Y_train: {}\".format(Y_train.shape))\n",
        "print(\"Y_test: {}\".format(Y_test.shape))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: (469, 30)\n",
            "X_test: (100, 30)\n",
            "Y_train: (469,)\n",
            "Y_test: (100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRmbAXnArNNl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "531e88dc-25e0-4a26-e469-22ac435b774c"
      },
      "source": [
        "#Building our baseline dummy classifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "clf = DummyClassifier()\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "#Predicting Results\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "#Calculating Resulta\n",
        "print(\"CM: \\n\",confusion_matrix(Y_test, y_pred))\n",
        "print(\"acc: {0}%\".format(accuracy_score(Y_test, y_pred) * 100))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CM: \n",
            " [[19 22]\n",
            " [17 42]]\n",
            "acc: 61.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc4kiZaYuyYV",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9nnHAUju0b9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "d3bdf71a-4910-4c4d-a35a-0b246f14fd5b"
      },
      "source": [
        "st=dt.now()\n",
        "logits = LogisticRegression(solver = 'liblinear')\n",
        "logits.fit(X_train, Y_train)\n",
        "print(\"Time taken to complete random search: \",dt.now()-st)\n",
        "\n",
        "pred_logits = logits.predict(X_test)\n",
        "\n",
        "#Model Evaluation\n",
        "logits_acc = accuracy_score(Y_test, pred_logits)\n",
        "print('Accuracy Score: ' + str(logits_acc))\n",
        "\n",
        "print('Precision Score: ' + str(precision_score(Y_test, pred_logits)))\n",
        "\n",
        "print('Recall Score: ' + str(recall_score(Y_test, pred_logits)))\n",
        "\n",
        "print('F1 Score: ' + str(f1_score(Y_test, pred_logits)))\n",
        "\n",
        "print('Classification Report: \\n' + str(classification_report(Y_test, pred_logits)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken to complete random search:  0:00:00.019376\n",
            "Accuracy Score: 0.95\n",
            "Precision Score: 0.9821428571428571\n",
            "Recall Score: 0.9322033898305084\n",
            "F1 Score: 0.9565217391304348\n",
            "Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.98      0.94        41\n",
            "           1       0.98      0.93      0.96        59\n",
            "\n",
            "    accuracy                           0.95       100\n",
            "   macro avg       0.95      0.95      0.95       100\n",
            "weighted avg       0.95      0.95      0.95       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DdqU07Ku5AB",
        "colab_type": "text"
      },
      "source": [
        "## K Nearest Neighbours Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTntgWpiu9Ix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "94e848c7-06de-4a8f-f918-6ec4fe0643a8"
      },
      "source": [
        "st=dt.now()\n",
        "knn = KNeighborsClassifier(n_neighbors = 10)\n",
        "knn.fit(X_train, Y_train)\n",
        "print(\"Time taken to complete random search: \",dt.now()-st)\n",
        "\n",
        "\n",
        "knn_pred = knn.predict(X_test)\n",
        "\n",
        "#Model Evaluation\n",
        "kacc = accuracy_score(Y_test, knn_pred)\n",
        "print('Accuracy Score: ' + str(kacc))\n",
        "\n",
        "print('Precision Score: ' + str(precision_score(Y_test, knn_pred)))\n",
        "\n",
        "print('Recall Score: ' + str(recall_score(Y_test, knn_pred)))\n",
        "\n",
        "print('F1 Score: ' + str(f1_score(Y_test, knn_pred)))\n",
        "\n",
        "print('Classification Report: \\n' + str(classification_report(Y_test, knn_pred)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken to complete random search:  0:00:00.011689\n",
            "Accuracy Score: 0.94\n",
            "Precision Score: 0.9491525423728814\n",
            "Recall Score: 0.9491525423728814\n",
            "F1 Score: 0.9491525423728814\n",
            "Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93        41\n",
            "           1       0.95      0.95      0.95        59\n",
            "\n",
            "    accuracy                           0.94       100\n",
            "   macro avg       0.94      0.94      0.94       100\n",
            "weighted avg       0.94      0.94      0.94       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb10b-QkvAH6",
        "colab_type": "text"
      },
      "source": [
        "## Liner Support Vector Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekjLnmoVvBqF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "f6c2de51-9ddd-4337-a199-daa67dbc5871"
      },
      "source": [
        "st=dt.now()\n",
        "l_svc = SVC(kernel = 'linear')\n",
        "l_svc.fit(X_train, Y_train)\n",
        "print(\"Time taken to complete random search: \",dt.now()-st)\n",
        "\n",
        "l_pred = l_svc.predict(X_test)\n",
        "\n",
        "#Model Evaluation\n",
        "lsvcacc = accuracy_score(Y_test, l_pred)\n",
        "print('Accuracy Score: ' + str(lsvcacc))\n",
        "\n",
        "print('Precision Score: ' + str(precision_score(Y_test, l_pred)))\n",
        "\n",
        "print('Recall Score: ' + str(recall_score(Y_test, l_pred)))\n",
        "\n",
        "print('F1 Score: ' + str(f1_score(Y_test, l_pred)))\n",
        "\n",
        "print('Classification Report: \\n' + str(classification_report(Y_test, l_pred)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken to complete random search:  0:00:02.474460\n",
            "Accuracy Score: 0.95\n",
            "Precision Score: 0.9821428571428571\n",
            "Recall Score: 0.9322033898305084\n",
            "F1 Score: 0.9565217391304348\n",
            "Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.98      0.94        41\n",
            "           1       0.98      0.93      0.96        59\n",
            "\n",
            "    accuracy                           0.95       100\n",
            "   macro avg       0.95      0.95      0.95       100\n",
            "weighted avg       0.95      0.95      0.95       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyeBkL0bvGA-",
        "colab_type": "text"
      },
      "source": [
        "##Kernel SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYhFtCxRvHeG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "603dbb68-3868-49ea-8ac4-222ba8f01136"
      },
      "source": [
        "st=dt.now()\n",
        "gk_svc = SVC(kernel = 'rbf')\n",
        "gk_svc.fit(X_train, Y_train)\n",
        "print(\"Time taken to complete random search: \",dt.now()-st)\n",
        "\n",
        "gk_pred = gk_svc.predict(X_test)\n",
        "\n",
        "#Model Evaluation\n",
        "ksvcaccacc = accuracy_score(Y_test, gk_pred)\n",
        "print('Accuracy Score: ' + str(ksvcaccacc))\n",
        "\n",
        "print('Precision Score: ' + str(precision_score(Y_test, gk_pred)))\n",
        "\n",
        "print('Recall Score: ' + str(recall_score(Y_test, gk_pred)))\n",
        "\n",
        "print('F1 Score: ' + str(f1_score(Y_test, gk_pred)))\n",
        "\n",
        "print('Classification Report: \\n' + str(classification_report(Y_test, gk_pred)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken to complete random search:  0:00:00.033044\n",
            "Accuracy Score: 0.59\n",
            "Precision Score: 0.59\n",
            "Recall Score: 1.0\n",
            "F1 Score: 0.7421383647798743\n",
            "Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        41\n",
            "           1       0.59      1.00      0.74        59\n",
            "\n",
            "    accuracy                           0.59       100\n",
            "   macro avg       0.29      0.50      0.37       100\n",
            "weighted avg       0.35      0.59      0.44       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVrSlVu3vJ_Q",
        "colab_type": "text"
      },
      "source": [
        "## Random Forest Classifierst\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7tyPCf5vLGf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "ab0d84be-b5b3-4368-d33d-7cbd9e0d9c28"
      },
      "source": [
        "st=dt.now()\n",
        "randomforest = RandomForestClassifier(n_estimators = 100, \n",
        "                                      random_state = 0)\n",
        "randomforest.fit(X_train, Y_train)\n",
        "print(\"Time taken to complete random search: \",dt.now()-st)\n",
        "\n",
        "random_pred = randomforest.predict(X_test)\n",
        "\n",
        "#Model Evaluation\n",
        "rmacc = accuracy_score(Y_test, random_pred)\n",
        "print('Accuracy Score: ' + str(rmacc))\n",
        "\n",
        "print('Precision Score: ' + str(precision_score(Y_test, random_pred)))\n",
        "\n",
        "print('Recall Score: ' + str(recall_score(Y_test, random_pred)))\n",
        "\n",
        "print('F1 Score: ' + str(f1_score(Y_test, random_pred)))\n",
        "\n",
        "print('Classification Report: \\n' + str(classification_report(Y_test, random_pred)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken to complete random search:  0:00:00.167032\n",
            "Accuracy Score: 0.96\n",
            "Precision Score: 0.9661016949152542\n",
            "Recall Score: 0.9661016949152542\n",
            "F1 Score: 0.9661016949152542\n",
            "Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95        41\n",
            "           1       0.97      0.97      0.97        59\n",
            "\n",
            "    accuracy                           0.96       100\n",
            "   macro avg       0.96      0.96      0.96       100\n",
            "weighted avg       0.96      0.96      0.96       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znuuHTFavN0y",
        "colab_type": "text"
      },
      "source": [
        "## Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63jo8qvwvPMR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "c502966d-21af-458a-c53a-cb311ef8288f"
      },
      "source": [
        "st=dt.now()\n",
        "decison = DecisionTreeClassifier(criterion = 'entropy', \n",
        "                                 random_state = 0)\n",
        "decison.fit(X_train, Y_train)\n",
        "print(\"Time taken to complete random search: \",dt.now()-st)\n",
        "\n",
        "decison_pred = decison.predict(X_test)\n",
        "\n",
        "#Model Evaluation\n",
        "dtacc = accuracy_score(Y_test, decison_pred)\n",
        "print('Accuracy Score: ' + str(dtacc))\n",
        "\n",
        "print('Precision Score: ' + str(precision_score(Y_test, decison_pred)))\n",
        "\n",
        "print('Recall Score: ' + str(recall_score(Y_test, decison_pred)))\n",
        "\n",
        "print('F1 Score: ' + str(f1_score(Y_test, decison_pred)))\n",
        "\n",
        "print('Classification Report: \\n' + str(classification_report(Y_test, decison_pred)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken to complete random search:  0:00:00.014401\n",
            "Accuracy Score: 0.9\n",
            "Precision Score: 0.9454545454545454\n",
            "Recall Score: 0.8813559322033898\n",
            "F1 Score: 0.9122807017543859\n",
            "Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.93      0.88        41\n",
            "           1       0.95      0.88      0.91        59\n",
            "\n",
            "    accuracy                           0.90       100\n",
            "   macro avg       0.89      0.90      0.90       100\n",
            "weighted avg       0.90      0.90      0.90       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXz62FAOvRXN",
        "colab_type": "text"
      },
      "source": [
        "##BernoulliNB Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKi0sfFfvVKV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "151d27c7-82d3-459d-c952-961305043787"
      },
      "source": [
        "st=dt.now()\n",
        "bernb = BernoulliNB()\n",
        "bernb.fit(X_train, Y_train)\n",
        "print(\"Time taken to complete random search: \",dt.now()-st)\n",
        "\n",
        "bernb_predict = bernb.predict(X_test)\n",
        "\n",
        "#Model Evaluation\n",
        "bncacc = accuracy_score(Y_test, bernb_predict)\n",
        "print('Accuracy Score: ' + str(bncacc))\n",
        "\n",
        "print('Precision Score: ' + str(precision_score(Y_test, bernb_predict)))\n",
        "\n",
        "print('Recall Score: ' + str(recall_score(Y_test, bernb_predict)))\n",
        "\n",
        "print('F1 Score: ' + str(f1_score(Y_test, bernb_predict)))\n",
        "\n",
        "print('Classification Report: \\n' + str(classification_report(Y_test, bernb_predict)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken to complete random search:  0:00:00.003578\n",
            "Accuracy Score: 0.59\n",
            "Precision Score: 0.59\n",
            "Recall Score: 1.0\n",
            "F1 Score: 0.7421383647798743\n",
            "Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        41\n",
            "           1       0.59      1.00      0.74        59\n",
            "\n",
            "    accuracy                           0.59       100\n",
            "   macro avg       0.29      0.50      0.37       100\n",
            "weighted avg       0.35      0.59      0.44       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EDdf5OOvRRU",
        "colab_type": "text"
      },
      "source": [
        "## MultinomialNB Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWId80-MvZQP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "58a46983-f7c8-455f-e5ef-cc7f084eda1b"
      },
      "source": [
        "st=dt.now()\n",
        "mulnb = MultinomialNB()\n",
        "mulnb.fit(X_train, Y_train)\n",
        "print(\"Time taken to complete random search: \",dt.now()-st)\n",
        "\n",
        "mulnb_predict = mulnb.predict(X_test)\n",
        "\n",
        "#Model Evaluation\n",
        "mulacc = accuracy_score(Y_test, mulnb_predict)\n",
        "print('Accuracy Score: ' + str(mulacc))\n",
        "\n",
        "print('Precision Score: ' + str(precision_score(Y_test, mulnb_predict)))\n",
        "\n",
        "print('Recall Score: ' + str(recall_score(Y_test, mulnb_predict)))\n",
        "\n",
        "print('F1 Score: ' + str(f1_score(Y_test, mulnb_predict)))\n",
        "\n",
        "print('Classification Report: \\n' + str(classification_report(Y_test, mulnb_predict)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken to complete random search:  0:00:00.005823\n",
            "Accuracy Score: 0.9\n",
            "Precision Score: 0.8656716417910447\n",
            "Recall Score: 0.9830508474576272\n",
            "F1 Score: 0.9206349206349207\n",
            "Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.78      0.86        41\n",
            "           1       0.87      0.98      0.92        59\n",
            "\n",
            "    accuracy                           0.90       100\n",
            "   macro avg       0.92      0.88      0.89       100\n",
            "weighted avg       0.91      0.90      0.90       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxFB4X9Qvahr",
        "colab_type": "text"
      },
      "source": [
        "## Artificial Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Jb6rBwavZK2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "662e43bf-e743-4934-8f78-efc2659506a4"
      },
      "source": [
        "#Building Our Model\n",
        "# Initialising the ANN\n",
        "classifier = Sequential()\n",
        "\n",
        "#Input and 1st Hidden Layer\n",
        "classifier.add(Dense(units = 20,\n",
        "                     activation = 'relu',\n",
        "                     kernel_initializer = 'uniform',\n",
        "                     input_dim = 30))\n",
        "classifier.add(Dropout(p = 0.1))\n",
        "\n",
        "\n",
        "#2nd Hidden Layer\n",
        "classifier.add(Dense(units = 20,\n",
        "                     activation = 'relu',\n",
        "                     kernel_initializer = 'uniform'))\n",
        "classifier.add(Dropout(p = 0.1))   \n",
        "\n",
        "\n",
        "#3rd Hidden Layer\n",
        "classifier.add(Dense(units = 20,\n",
        "                     activation = 'relu',\n",
        "                     kernel_initializer = 'uniform'))\n",
        "classifier.add(Dropout(p = 0.2))               \n",
        "\n",
        "#Output Layer\n",
        "classifier.add(Dense(units = 1,\n",
        "                     activation = 'sigmoid',\n",
        "                     kernel_initializer = 'uniform'))\n",
        "               \n",
        "classifier.compile(optimizer = 'adam',\n",
        "                   loss = 'binary_crossentropy',\n",
        "                   metrics = ['accuracy']) \n",
        "classifier.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 20)                620       \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 1,481\n",
            "Trainable params: 1,481\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfHO3yJ0xzpW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2371d4c5-d4ae-4ff2-a96e-29824b57ffb6"
      },
      "source": [
        "#training our ANN Model\n",
        "history = classifier.fit(X_train, \n",
        "                         Y_train, \n",
        "                         batch_size = 16, \n",
        "                         epochs = 500, \n",
        "                         validation_split=0.15)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 398 samples, validate on 71 samples\n",
            "Epoch 1/500\n",
            "398/398 [==============================] - 1s 2ms/step - loss: 0.6872 - acc: 0.6508 - val_loss: 0.6776 - val_acc: 0.3803\n",
            "Epoch 2/500\n",
            "398/398 [==============================] - 0s 130us/step - loss: 0.6627 - acc: 0.5151 - val_loss: 0.6354 - val_acc: 0.4366\n",
            "Epoch 3/500\n",
            "398/398 [==============================] - 0s 129us/step - loss: 0.5880 - acc: 0.7588 - val_loss: 0.4816 - val_acc: 0.8873\n",
            "Epoch 4/500\n",
            "398/398 [==============================] - 0s 120us/step - loss: 0.4333 - acc: 0.8492 - val_loss: 0.3696 - val_acc: 0.8732\n",
            "Epoch 5/500\n",
            "398/398 [==============================] - 0s 133us/step - loss: 0.3063 - acc: 0.8869 - val_loss: 0.4422 - val_acc: 0.8592\n",
            "Epoch 6/500\n",
            "398/398 [==============================] - 0s 128us/step - loss: 0.2836 - acc: 0.8920 - val_loss: 0.2697 - val_acc: 0.9014\n",
            "Epoch 7/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.2890 - acc: 0.8995 - val_loss: 0.2776 - val_acc: 0.9155\n",
            "Epoch 8/500\n",
            "398/398 [==============================] - 0s 118us/step - loss: 0.2617 - acc: 0.8945 - val_loss: 0.3368 - val_acc: 0.8732\n",
            "Epoch 9/500\n",
            "398/398 [==============================] - 0s 124us/step - loss: 0.2874 - acc: 0.8894 - val_loss: 0.2755 - val_acc: 0.9014\n",
            "Epoch 10/500\n",
            "398/398 [==============================] - 0s 125us/step - loss: 0.2551 - acc: 0.9095 - val_loss: 0.2638 - val_acc: 0.9014\n",
            "Epoch 11/500\n",
            "398/398 [==============================] - 0s 122us/step - loss: 0.2342 - acc: 0.9146 - val_loss: 0.2511 - val_acc: 0.9155\n",
            "Epoch 12/500\n",
            "398/398 [==============================] - 0s 116us/step - loss: 0.2311 - acc: 0.9146 - val_loss: 0.2576 - val_acc: 0.9155\n",
            "Epoch 13/500\n",
            "398/398 [==============================] - 0s 121us/step - loss: 0.2825 - acc: 0.8894 - val_loss: 0.4912 - val_acc: 0.8732\n",
            "Epoch 14/500\n",
            "398/398 [==============================] - 0s 123us/step - loss: 0.2792 - acc: 0.8894 - val_loss: 0.3248 - val_acc: 0.8732\n",
            "Epoch 15/500\n",
            "398/398 [==============================] - 0s 137us/step - loss: 0.2404 - acc: 0.9095 - val_loss: 0.3338 - val_acc: 0.8873\n",
            "Epoch 16/500\n",
            "398/398 [==============================] - 0s 132us/step - loss: 0.2302 - acc: 0.8894 - val_loss: 0.3180 - val_acc: 0.8732\n",
            "Epoch 17/500\n",
            "398/398 [==============================] - 0s 125us/step - loss: 0.2338 - acc: 0.9070 - val_loss: 0.2852 - val_acc: 0.9014\n",
            "Epoch 18/500\n",
            "398/398 [==============================] - 0s 125us/step - loss: 0.2181 - acc: 0.9121 - val_loss: 0.2573 - val_acc: 0.8873\n",
            "Epoch 19/500\n",
            "398/398 [==============================] - 0s 125us/step - loss: 0.2393 - acc: 0.8920 - val_loss: 0.2689 - val_acc: 0.8873\n",
            "Epoch 20/500\n",
            "398/398 [==============================] - 0s 129us/step - loss: 0.2157 - acc: 0.9146 - val_loss: 0.2589 - val_acc: 0.8873\n",
            "Epoch 21/500\n",
            "398/398 [==============================] - 0s 133us/step - loss: 0.2283 - acc: 0.8995 - val_loss: 0.2602 - val_acc: 0.9014\n",
            "Epoch 22/500\n",
            "398/398 [==============================] - 0s 130us/step - loss: 0.2354 - acc: 0.9146 - val_loss: 0.2749 - val_acc: 0.9155\n",
            "Epoch 23/500\n",
            "398/398 [==============================] - 0s 127us/step - loss: 0.2104 - acc: 0.9271 - val_loss: 0.2534 - val_acc: 0.9014\n",
            "Epoch 24/500\n",
            "398/398 [==============================] - 0s 123us/step - loss: 0.2038 - acc: 0.9196 - val_loss: 0.2467 - val_acc: 0.9155\n",
            "Epoch 25/500\n",
            "398/398 [==============================] - 0s 118us/step - loss: 0.2015 - acc: 0.9020 - val_loss: 0.2431 - val_acc: 0.9014\n",
            "Epoch 26/500\n",
            "398/398 [==============================] - 0s 115us/step - loss: 0.1784 - acc: 0.9221 - val_loss: 0.2406 - val_acc: 0.9014\n",
            "Epoch 27/500\n",
            "398/398 [==============================] - 0s 125us/step - loss: 0.1823 - acc: 0.9296 - val_loss: 0.2547 - val_acc: 0.9296\n",
            "Epoch 28/500\n",
            "398/398 [==============================] - 0s 120us/step - loss: 0.2223 - acc: 0.9045 - val_loss: 0.2458 - val_acc: 0.9155\n",
            "Epoch 29/500\n",
            "398/398 [==============================] - 0s 122us/step - loss: 0.2180 - acc: 0.9121 - val_loss: 0.2527 - val_acc: 0.9155\n",
            "Epoch 30/500\n",
            "398/398 [==============================] - 0s 122us/step - loss: 0.2132 - acc: 0.9121 - val_loss: 0.2344 - val_acc: 0.9155\n",
            "Epoch 31/500\n",
            "398/398 [==============================] - 0s 128us/step - loss: 0.1776 - acc: 0.9246 - val_loss: 0.2399 - val_acc: 0.8873\n",
            "Epoch 32/500\n",
            "398/398 [==============================] - 0s 126us/step - loss: 0.2271 - acc: 0.9221 - val_loss: 0.2246 - val_acc: 0.9155\n",
            "Epoch 33/500\n",
            "398/398 [==============================] - 0s 116us/step - loss: 0.1758 - acc: 0.9146 - val_loss: 0.2569 - val_acc: 0.9155\n",
            "Epoch 34/500\n",
            "398/398 [==============================] - 0s 122us/step - loss: 0.1787 - acc: 0.9171 - val_loss: 0.2557 - val_acc: 0.9014\n",
            "Epoch 35/500\n",
            "398/398 [==============================] - 0s 126us/step - loss: 0.1804 - acc: 0.9221 - val_loss: 0.2299 - val_acc: 0.9296\n",
            "Epoch 36/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1778 - acc: 0.9221 - val_loss: 0.2806 - val_acc: 0.9155\n",
            "Epoch 37/500\n",
            "398/398 [==============================] - 0s 124us/step - loss: 0.2060 - acc: 0.9146 - val_loss: 0.2247 - val_acc: 0.9155\n",
            "Epoch 38/500\n",
            "398/398 [==============================] - 0s 122us/step - loss: 0.1766 - acc: 0.9296 - val_loss: 0.2312 - val_acc: 0.9155\n",
            "Epoch 39/500\n",
            "398/398 [==============================] - 0s 126us/step - loss: 0.1857 - acc: 0.9095 - val_loss: 0.2415 - val_acc: 0.9155\n",
            "Epoch 40/500\n",
            "398/398 [==============================] - 0s 118us/step - loss: 0.1612 - acc: 0.9296 - val_loss: 0.2580 - val_acc: 0.9014\n",
            "Epoch 41/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1847 - acc: 0.9171 - val_loss: 0.3192 - val_acc: 0.9155\n",
            "Epoch 42/500\n",
            "398/398 [==============================] - 0s 124us/step - loss: 0.1561 - acc: 0.9296 - val_loss: 0.2297 - val_acc: 0.9155\n",
            "Epoch 43/500\n",
            "398/398 [==============================] - 0s 128us/step - loss: 0.2122 - acc: 0.9121 - val_loss: 0.2203 - val_acc: 0.9155\n",
            "Epoch 44/500\n",
            "398/398 [==============================] - 0s 117us/step - loss: 0.1773 - acc: 0.9296 - val_loss: 0.2611 - val_acc: 0.9155\n",
            "Epoch 45/500\n",
            "398/398 [==============================] - 0s 122us/step - loss: 0.1778 - acc: 0.9322 - val_loss: 0.2521 - val_acc: 0.9014\n",
            "Epoch 46/500\n",
            "398/398 [==============================] - 0s 120us/step - loss: 0.1712 - acc: 0.9271 - val_loss: 0.2597 - val_acc: 0.9014\n",
            "Epoch 47/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1650 - acc: 0.9271 - val_loss: 0.2625 - val_acc: 0.9155\n",
            "Epoch 48/500\n",
            "398/398 [==============================] - 0s 130us/step - loss: 0.1623 - acc: 0.9296 - val_loss: 0.4091 - val_acc: 0.8873\n",
            "Epoch 49/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.1734 - acc: 0.9271 - val_loss: 0.2728 - val_acc: 0.9014\n",
            "Epoch 50/500\n",
            "398/398 [==============================] - 0s 112us/step - loss: 0.1625 - acc: 0.9322 - val_loss: 0.3444 - val_acc: 0.8873\n",
            "Epoch 51/500\n",
            "398/398 [==============================] - 0s 117us/step - loss: 0.1646 - acc: 0.9221 - val_loss: 0.2928 - val_acc: 0.9296\n",
            "Epoch 52/500\n",
            "398/398 [==============================] - 0s 118us/step - loss: 0.1716 - acc: 0.9221 - val_loss: 0.3698 - val_acc: 0.9014\n",
            "Epoch 53/500\n",
            "398/398 [==============================] - 0s 115us/step - loss: 0.1806 - acc: 0.9271 - val_loss: 0.2410 - val_acc: 0.9014\n",
            "Epoch 54/500\n",
            "398/398 [==============================] - 0s 136us/step - loss: 0.1615 - acc: 0.9372 - val_loss: 0.2620 - val_acc: 0.8732\n",
            "Epoch 55/500\n",
            "398/398 [==============================] - 0s 119us/step - loss: 0.1921 - acc: 0.9322 - val_loss: 0.2198 - val_acc: 0.9155\n",
            "Epoch 56/500\n",
            "398/398 [==============================] - 0s 122us/step - loss: 0.1592 - acc: 0.9322 - val_loss: 0.2437 - val_acc: 0.9155\n",
            "Epoch 57/500\n",
            "398/398 [==============================] - 0s 123us/step - loss: 0.1537 - acc: 0.9246 - val_loss: 0.2353 - val_acc: 0.9014\n",
            "Epoch 58/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1585 - acc: 0.9347 - val_loss: 0.2189 - val_acc: 0.9014\n",
            "Epoch 59/500\n",
            "398/398 [==============================] - 0s 123us/step - loss: 0.1388 - acc: 0.9347 - val_loss: 0.2437 - val_acc: 0.9014\n",
            "Epoch 60/500\n",
            "398/398 [==============================] - 0s 120us/step - loss: 0.1576 - acc: 0.9296 - val_loss: 0.2095 - val_acc: 0.9296\n",
            "Epoch 61/500\n",
            "398/398 [==============================] - 0s 144us/step - loss: 0.1620 - acc: 0.9347 - val_loss: 0.3606 - val_acc: 0.9014\n",
            "Epoch 62/500\n",
            "398/398 [==============================] - 0s 121us/step - loss: 0.1978 - acc: 0.9045 - val_loss: 0.2788 - val_acc: 0.9155\n",
            "Epoch 63/500\n",
            "398/398 [==============================] - 0s 114us/step - loss: 0.1527 - acc: 0.9271 - val_loss: 0.2119 - val_acc: 0.9014\n",
            "Epoch 64/500\n",
            "398/398 [==============================] - 0s 135us/step - loss: 0.1692 - acc: 0.9347 - val_loss: 0.2565 - val_acc: 0.9014\n",
            "Epoch 65/500\n",
            "398/398 [==============================] - 0s 112us/step - loss: 0.1524 - acc: 0.9347 - val_loss: 0.2687 - val_acc: 0.9014\n",
            "Epoch 66/500\n",
            "398/398 [==============================] - 0s 116us/step - loss: 0.1609 - acc: 0.9372 - val_loss: 0.2131 - val_acc: 0.9155\n",
            "Epoch 67/500\n",
            "398/398 [==============================] - 0s 119us/step - loss: 0.1734 - acc: 0.9322 - val_loss: 0.2724 - val_acc: 0.9014\n",
            "Epoch 68/500\n",
            "398/398 [==============================] - 0s 121us/step - loss: 0.1396 - acc: 0.9372 - val_loss: 0.3034 - val_acc: 0.8873\n",
            "Epoch 69/500\n",
            "398/398 [==============================] - 0s 115us/step - loss: 0.1570 - acc: 0.9296 - val_loss: 0.2055 - val_acc: 0.9296\n",
            "Epoch 70/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1997 - acc: 0.9246 - val_loss: 0.2349 - val_acc: 0.8873\n",
            "Epoch 71/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.1706 - acc: 0.9296 - val_loss: 0.2606 - val_acc: 0.8873\n",
            "Epoch 72/500\n",
            "398/398 [==============================] - 0s 120us/step - loss: 0.1757 - acc: 0.9347 - val_loss: 0.2530 - val_acc: 0.9155\n",
            "Epoch 73/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1659 - acc: 0.9397 - val_loss: 0.3241 - val_acc: 0.9296\n",
            "Epoch 74/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1615 - acc: 0.9347 - val_loss: 0.2142 - val_acc: 0.9155\n",
            "Epoch 75/500\n",
            "398/398 [==============================] - 0s 114us/step - loss: 0.1464 - acc: 0.9221 - val_loss: 0.2211 - val_acc: 0.9155\n",
            "Epoch 76/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1612 - acc: 0.9422 - val_loss: 0.2069 - val_acc: 0.9155\n",
            "Epoch 77/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1516 - acc: 0.9497 - val_loss: 0.2752 - val_acc: 0.9155\n",
            "Epoch 78/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1393 - acc: 0.9322 - val_loss: 0.2830 - val_acc: 0.9296\n",
            "Epoch 79/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1392 - acc: 0.9372 - val_loss: 0.2062 - val_acc: 0.9014\n",
            "Epoch 80/500\n",
            "398/398 [==============================] - 0s 114us/step - loss: 0.1423 - acc: 0.9372 - val_loss: 0.2675 - val_acc: 0.9296\n",
            "Epoch 81/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.1434 - acc: 0.9347 - val_loss: 0.3685 - val_acc: 0.9296\n",
            "Epoch 82/500\n",
            "398/398 [==============================] - 0s 116us/step - loss: 0.1778 - acc: 0.9246 - val_loss: 0.2077 - val_acc: 0.9014\n",
            "Epoch 83/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1736 - acc: 0.9246 - val_loss: 0.2135 - val_acc: 0.9155\n",
            "Epoch 84/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.1513 - acc: 0.9372 - val_loss: 0.2330 - val_acc: 0.9155\n",
            "Epoch 85/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.1365 - acc: 0.9372 - val_loss: 0.1930 - val_acc: 0.9155\n",
            "Epoch 86/500\n",
            "398/398 [==============================] - 0s 101us/step - loss: 0.1554 - acc: 0.9472 - val_loss: 0.2167 - val_acc: 0.9155\n",
            "Epoch 87/500\n",
            "398/398 [==============================] - 0s 126us/step - loss: 0.1423 - acc: 0.9296 - val_loss: 0.4316 - val_acc: 0.9296\n",
            "Epoch 88/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.1574 - acc: 0.9372 - val_loss: 0.2218 - val_acc: 0.9014\n",
            "Epoch 89/500\n",
            "398/398 [==============================] - 0s 114us/step - loss: 0.1417 - acc: 0.9397 - val_loss: 0.2033 - val_acc: 0.9296\n",
            "Epoch 90/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1484 - acc: 0.9322 - val_loss: 0.2079 - val_acc: 0.9155\n",
            "Epoch 91/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1467 - acc: 0.9472 - val_loss: 0.1828 - val_acc: 0.9296\n",
            "Epoch 92/500\n",
            "398/398 [==============================] - 0s 114us/step - loss: 0.1810 - acc: 0.9296 - val_loss: 0.2551 - val_acc: 0.8873\n",
            "Epoch 93/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1595 - acc: 0.9372 - val_loss: 0.1935 - val_acc: 0.9296\n",
            "Epoch 94/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1453 - acc: 0.9447 - val_loss: 0.2519 - val_acc: 0.9296\n",
            "Epoch 95/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1548 - acc: 0.9472 - val_loss: 0.3054 - val_acc: 0.9296\n",
            "Epoch 96/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.1459 - acc: 0.9347 - val_loss: 0.1797 - val_acc: 0.9155\n",
            "Epoch 97/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1452 - acc: 0.9497 - val_loss: 0.1892 - val_acc: 0.9155\n",
            "Epoch 98/500\n",
            "398/398 [==============================] - 0s 114us/step - loss: 0.1341 - acc: 0.9372 - val_loss: 0.2576 - val_acc: 0.9155\n",
            "Epoch 99/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1299 - acc: 0.9472 - val_loss: 0.2878 - val_acc: 0.9296\n",
            "Epoch 100/500\n",
            "398/398 [==============================] - 0s 112us/step - loss: 0.1336 - acc: 0.9422 - val_loss: 0.2436 - val_acc: 0.9014\n",
            "Epoch 101/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.1358 - acc: 0.9372 - val_loss: 0.2004 - val_acc: 0.9014\n",
            "Epoch 102/500\n",
            "398/398 [==============================] - 0s 123us/step - loss: 0.1267 - acc: 0.9497 - val_loss: 0.2570 - val_acc: 0.9014\n",
            "Epoch 103/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1440 - acc: 0.9397 - val_loss: 0.1940 - val_acc: 0.9014\n",
            "Epoch 104/500\n",
            "398/398 [==============================] - 0s 105us/step - loss: 0.1343 - acc: 0.9397 - val_loss: 0.2048 - val_acc: 0.9014\n",
            "Epoch 105/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1304 - acc: 0.9472 - val_loss: 0.3312 - val_acc: 0.8169\n",
            "Epoch 106/500\n",
            "398/398 [==============================] - 0s 104us/step - loss: 0.1987 - acc: 0.9045 - val_loss: 0.2196 - val_acc: 0.9155\n",
            "Epoch 107/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1577 - acc: 0.9322 - val_loss: 0.1876 - val_acc: 0.9296\n",
            "Epoch 108/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1345 - acc: 0.9347 - val_loss: 0.2324 - val_acc: 0.9155\n",
            "Epoch 109/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1253 - acc: 0.9472 - val_loss: 0.2451 - val_acc: 0.9014\n",
            "Epoch 110/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1266 - acc: 0.9422 - val_loss: 0.1959 - val_acc: 0.9155\n",
            "Epoch 111/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.1307 - acc: 0.9472 - val_loss: 0.2587 - val_acc: 0.9014\n",
            "Epoch 112/500\n",
            "398/398 [==============================] - 0s 104us/step - loss: 0.1327 - acc: 0.9422 - val_loss: 0.2242 - val_acc: 0.9014\n",
            "Epoch 113/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1188 - acc: 0.9472 - val_loss: 0.2852 - val_acc: 0.9155\n",
            "Epoch 114/500\n",
            "398/398 [==============================] - 0s 102us/step - loss: 0.1175 - acc: 0.9472 - val_loss: 0.1960 - val_acc: 0.9014\n",
            "Epoch 115/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1576 - acc: 0.9296 - val_loss: 0.1976 - val_acc: 0.9014\n",
            "Epoch 116/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1352 - acc: 0.9271 - val_loss: 0.2829 - val_acc: 0.9014\n",
            "Epoch 117/500\n",
            "398/398 [==============================] - 0s 118us/step - loss: 0.1447 - acc: 0.9372 - val_loss: 0.2771 - val_acc: 0.9155\n",
            "Epoch 118/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1287 - acc: 0.9472 - val_loss: 0.1854 - val_acc: 0.9155\n",
            "Epoch 119/500\n",
            "398/398 [==============================] - 0s 116us/step - loss: 0.1503 - acc: 0.9372 - val_loss: 0.2123 - val_acc: 0.9014\n",
            "Epoch 120/500\n",
            "398/398 [==============================] - 0s 104us/step - loss: 0.1507 - acc: 0.9397 - val_loss: 0.4886 - val_acc: 0.9296\n",
            "Epoch 121/500\n",
            "398/398 [==============================] - 0s 114us/step - loss: 0.2205 - acc: 0.9171 - val_loss: 0.2282 - val_acc: 0.9296\n",
            "Epoch 122/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1583 - acc: 0.9472 - val_loss: 0.2967 - val_acc: 0.9296\n",
            "Epoch 123/500\n",
            "398/398 [==============================] - 0s 115us/step - loss: 0.1548 - acc: 0.9372 - val_loss: 0.2166 - val_acc: 0.9296\n",
            "Epoch 124/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1272 - acc: 0.9573 - val_loss: 0.1868 - val_acc: 0.9437\n",
            "Epoch 125/500\n",
            "398/398 [==============================] - 0s 114us/step - loss: 0.1211 - acc: 0.9422 - val_loss: 0.2248 - val_acc: 0.9296\n",
            "Epoch 126/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1168 - acc: 0.9497 - val_loss: 0.2914 - val_acc: 0.9155\n",
            "Epoch 127/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1407 - acc: 0.9246 - val_loss: 0.1799 - val_acc: 0.9155\n",
            "Epoch 128/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1209 - acc: 0.9497 - val_loss: 0.3221 - val_acc: 0.9296\n",
            "Epoch 129/500\n",
            "398/398 [==============================] - 0s 105us/step - loss: 0.1269 - acc: 0.9322 - val_loss: 0.2390 - val_acc: 0.9155\n",
            "Epoch 130/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1422 - acc: 0.9497 - val_loss: 0.2513 - val_acc: 0.9296\n",
            "Epoch 131/500\n",
            "398/398 [==============================] - 0s 103us/step - loss: 0.1445 - acc: 0.9347 - val_loss: 0.2816 - val_acc: 0.9296\n",
            "Epoch 132/500\n",
            "398/398 [==============================] - 0s 116us/step - loss: 0.1512 - acc: 0.9397 - val_loss: 0.2288 - val_acc: 0.9296\n",
            "Epoch 133/500\n",
            "398/398 [==============================] - 0s 117us/step - loss: 0.1310 - acc: 0.9422 - val_loss: 0.1763 - val_acc: 0.9437\n",
            "Epoch 134/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.1404 - acc: 0.9422 - val_loss: 0.2912 - val_acc: 0.9296\n",
            "Epoch 135/500\n",
            "398/398 [==============================] - 0s 114us/step - loss: 0.1516 - acc: 0.9397 - val_loss: 0.2167 - val_acc: 0.9296\n",
            "Epoch 136/500\n",
            "398/398 [==============================] - 0s 139us/step - loss: 0.1377 - acc: 0.9497 - val_loss: 0.2233 - val_acc: 0.9155\n",
            "Epoch 137/500\n",
            "398/398 [==============================] - 0s 125us/step - loss: 0.1332 - acc: 0.9422 - val_loss: 0.3084 - val_acc: 0.9296\n",
            "Epoch 138/500\n",
            "398/398 [==============================] - 0s 116us/step - loss: 0.1355 - acc: 0.9246 - val_loss: 0.2228 - val_acc: 0.9296\n",
            "Epoch 139/500\n",
            "398/398 [==============================] - 0s 122us/step - loss: 0.1319 - acc: 0.9322 - val_loss: 0.1748 - val_acc: 0.9296\n",
            "Epoch 140/500\n",
            "398/398 [==============================] - 0s 103us/step - loss: 0.1298 - acc: 0.9397 - val_loss: 0.2156 - val_acc: 0.9296\n",
            "Epoch 141/500\n",
            "398/398 [==============================] - 0s 126us/step - loss: 0.1140 - acc: 0.9598 - val_loss: 0.3168 - val_acc: 0.9155\n",
            "Epoch 142/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.1111 - acc: 0.9523 - val_loss: 0.4147 - val_acc: 0.9014\n",
            "Epoch 143/500\n",
            "398/398 [==============================] - 0s 114us/step - loss: 0.2305 - acc: 0.9171 - val_loss: 0.2251 - val_acc: 0.8873\n",
            "Epoch 144/500\n",
            "398/398 [==============================] - 0s 103us/step - loss: 0.1409 - acc: 0.9447 - val_loss: 0.1720 - val_acc: 0.9296\n",
            "Epoch 145/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.1335 - acc: 0.9422 - val_loss: 0.1923 - val_acc: 0.9155\n",
            "Epoch 146/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1336 - acc: 0.9523 - val_loss: 0.2086 - val_acc: 0.9296\n",
            "Epoch 147/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1330 - acc: 0.9472 - val_loss: 0.1898 - val_acc: 0.9296\n",
            "Epoch 148/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.1707 - acc: 0.9397 - val_loss: 0.1686 - val_acc: 0.9155\n",
            "Epoch 149/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.1898 - acc: 0.9121 - val_loss: 0.1717 - val_acc: 0.9437\n",
            "Epoch 150/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1531 - acc: 0.9447 - val_loss: 0.2056 - val_acc: 0.9296\n",
            "Epoch 151/500\n",
            "398/398 [==============================] - 0s 104us/step - loss: 0.1291 - acc: 0.9422 - val_loss: 0.2483 - val_acc: 0.9296\n",
            "Epoch 152/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1029 - acc: 0.9548 - val_loss: 0.3722 - val_acc: 0.9296\n",
            "Epoch 153/500\n",
            "398/398 [==============================] - 0s 114us/step - loss: 0.1091 - acc: 0.9523 - val_loss: 0.1857 - val_acc: 0.9296\n",
            "Epoch 154/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1287 - acc: 0.9347 - val_loss: 0.2538 - val_acc: 0.9296\n",
            "Epoch 155/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1399 - acc: 0.9422 - val_loss: 0.2701 - val_acc: 0.9155\n",
            "Epoch 156/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1731 - acc: 0.9372 - val_loss: 0.2158 - val_acc: 0.9014\n",
            "Epoch 157/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.1452 - acc: 0.9372 - val_loss: 0.2784 - val_acc: 0.9296\n",
            "Epoch 158/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.1145 - acc: 0.9523 - val_loss: 0.2169 - val_acc: 0.9155\n",
            "Epoch 159/500\n",
            "398/398 [==============================] - 0s 105us/step - loss: 0.1277 - acc: 0.9397 - val_loss: 0.4113 - val_acc: 0.9296\n",
            "Epoch 160/500\n",
            "398/398 [==============================] - 0s 125us/step - loss: 0.1387 - acc: 0.9447 - val_loss: 0.2309 - val_acc: 0.9296\n",
            "Epoch 161/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1293 - acc: 0.9422 - val_loss: 0.3144 - val_acc: 0.9296\n",
            "Epoch 162/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1352 - acc: 0.9673 - val_loss: 0.1678 - val_acc: 0.9296\n",
            "Epoch 163/500\n",
            "398/398 [==============================] - 0s 112us/step - loss: 0.1262 - acc: 0.9472 - val_loss: 0.2026 - val_acc: 0.9155\n",
            "Epoch 164/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1402 - acc: 0.9422 - val_loss: 0.2004 - val_acc: 0.9155\n",
            "Epoch 165/500\n",
            "398/398 [==============================] - 0s 115us/step - loss: 0.1167 - acc: 0.9497 - val_loss: 0.2492 - val_acc: 0.9296\n",
            "Epoch 166/500\n",
            "398/398 [==============================] - 0s 103us/step - loss: 0.1497 - acc: 0.9372 - val_loss: 0.1762 - val_acc: 0.9296\n",
            "Epoch 167/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1153 - acc: 0.9447 - val_loss: 0.2227 - val_acc: 0.9014\n",
            "Epoch 168/500\n",
            "398/398 [==============================] - 0s 105us/step - loss: 0.1596 - acc: 0.9347 - val_loss: 0.1687 - val_acc: 0.9155\n",
            "Epoch 169/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1641 - acc: 0.9397 - val_loss: 0.1841 - val_acc: 0.9296\n",
            "Epoch 170/500\n",
            "398/398 [==============================] - 0s 115us/step - loss: 0.1350 - acc: 0.9472 - val_loss: 0.2225 - val_acc: 0.9296\n",
            "Epoch 171/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.1170 - acc: 0.9548 - val_loss: 0.2239 - val_acc: 0.9296\n",
            "Epoch 172/500\n",
            "398/398 [==============================] - 0s 104us/step - loss: 0.1118 - acc: 0.9573 - val_loss: 0.1829 - val_acc: 0.9014\n",
            "Epoch 173/500\n",
            "398/398 [==============================] - 0s 115us/step - loss: 0.1507 - acc: 0.9296 - val_loss: 0.2041 - val_acc: 0.9296\n",
            "Epoch 174/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1119 - acc: 0.9548 - val_loss: 0.3413 - val_acc: 0.9296\n",
            "Epoch 175/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1439 - acc: 0.9523 - val_loss: 0.1966 - val_acc: 0.9014\n",
            "Epoch 176/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1115 - acc: 0.9422 - val_loss: 0.2132 - val_acc: 0.9014\n",
            "Epoch 177/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1172 - acc: 0.9523 - val_loss: 0.1978 - val_acc: 0.9296\n",
            "Epoch 178/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1331 - acc: 0.9397 - val_loss: 0.2523 - val_acc: 0.9296\n",
            "Epoch 179/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.1295 - acc: 0.9472 - val_loss: 0.1825 - val_acc: 0.9296\n",
            "Epoch 180/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.1583 - acc: 0.9347 - val_loss: 0.1820 - val_acc: 0.9296\n",
            "Epoch 181/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1336 - acc: 0.9497 - val_loss: 0.3065 - val_acc: 0.9014\n",
            "Epoch 182/500\n",
            "398/398 [==============================] - 0s 112us/step - loss: 0.1242 - acc: 0.9422 - val_loss: 0.2350 - val_acc: 0.9296\n",
            "Epoch 183/500\n",
            "398/398 [==============================] - 0s 120us/step - loss: 0.1127 - acc: 0.9573 - val_loss: 0.2337 - val_acc: 0.9296\n",
            "Epoch 184/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1422 - acc: 0.9322 - val_loss: 0.2076 - val_acc: 0.9296\n",
            "Epoch 185/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1242 - acc: 0.9296 - val_loss: 0.1867 - val_acc: 0.9296\n",
            "Epoch 186/500\n",
            "398/398 [==============================] - 0s 105us/step - loss: 0.1067 - acc: 0.9548 - val_loss: 0.3119 - val_acc: 0.9296\n",
            "Epoch 187/500\n",
            "398/398 [==============================] - 0s 105us/step - loss: 0.1441 - acc: 0.9447 - val_loss: 0.1710 - val_acc: 0.9155\n",
            "Epoch 188/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1414 - acc: 0.9397 - val_loss: 0.1773 - val_acc: 0.9155\n",
            "Epoch 189/500\n",
            "398/398 [==============================] - 0s 104us/step - loss: 0.1301 - acc: 0.9372 - val_loss: 0.1910 - val_acc: 0.9155\n",
            "Epoch 190/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.1097 - acc: 0.9422 - val_loss: 0.2462 - val_acc: 0.9296\n",
            "Epoch 191/500\n",
            "398/398 [==============================] - 0s 103us/step - loss: 0.1093 - acc: 0.9497 - val_loss: 0.2209 - val_acc: 0.9296\n",
            "Epoch 192/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.1200 - acc: 0.9447 - val_loss: 0.2625 - val_acc: 0.9296\n",
            "Epoch 193/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1207 - acc: 0.9422 - val_loss: 0.2314 - val_acc: 0.9155\n",
            "Epoch 194/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1066 - acc: 0.9573 - val_loss: 0.2259 - val_acc: 0.9296\n",
            "Epoch 195/500\n",
            "398/398 [==============================] - 0s 115us/step - loss: 0.1135 - acc: 0.9548 - val_loss: 0.2495 - val_acc: 0.9296\n",
            "Epoch 196/500\n",
            "398/398 [==============================] - 0s 112us/step - loss: 0.1111 - acc: 0.9523 - val_loss: 0.1755 - val_acc: 0.9296\n",
            "Epoch 197/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1483 - acc: 0.9447 - val_loss: 0.1734 - val_acc: 0.9155\n",
            "Epoch 198/500\n",
            "398/398 [==============================] - 0s 123us/step - loss: 0.1102 - acc: 0.9598 - val_loss: 0.4310 - val_acc: 0.9014\n",
            "Epoch 199/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1487 - acc: 0.9246 - val_loss: 0.1734 - val_acc: 0.9296\n",
            "Epoch 200/500\n",
            "398/398 [==============================] - 0s 112us/step - loss: 0.1155 - acc: 0.9573 - val_loss: 0.2283 - val_acc: 0.9296\n",
            "Epoch 201/500\n",
            "398/398 [==============================] - 0s 102us/step - loss: 0.0970 - acc: 0.9648 - val_loss: 0.1819 - val_acc: 0.9014\n",
            "Epoch 202/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1392 - acc: 0.9472 - val_loss: 0.1560 - val_acc: 0.9296\n",
            "Epoch 203/500\n",
            "398/398 [==============================] - 0s 103us/step - loss: 0.1229 - acc: 0.9447 - val_loss: 0.1717 - val_acc: 0.9155\n",
            "Epoch 204/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1560 - acc: 0.9347 - val_loss: 0.2053 - val_acc: 0.9155\n",
            "Epoch 205/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1263 - acc: 0.9397 - val_loss: 0.1916 - val_acc: 0.9014\n",
            "Epoch 206/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1226 - acc: 0.9397 - val_loss: 0.1903 - val_acc: 0.9155\n",
            "Epoch 207/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1257 - acc: 0.9497 - val_loss: 0.1624 - val_acc: 0.9437\n",
            "Epoch 208/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1432 - acc: 0.9422 - val_loss: 0.2315 - val_acc: 0.9296\n",
            "Epoch 209/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1131 - acc: 0.9497 - val_loss: 0.1819 - val_acc: 0.9155\n",
            "Epoch 210/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1243 - acc: 0.9447 - val_loss: 0.1912 - val_acc: 0.9014\n",
            "Epoch 211/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1175 - acc: 0.9523 - val_loss: 0.1648 - val_acc: 0.9296\n",
            "Epoch 212/500\n",
            "398/398 [==============================] - 0s 125us/step - loss: 0.1596 - acc: 0.9322 - val_loss: 0.1596 - val_acc: 0.9296\n",
            "Epoch 213/500\n",
            "398/398 [==============================] - 0s 112us/step - loss: 0.1224 - acc: 0.9497 - val_loss: 0.1984 - val_acc: 0.9296\n",
            "Epoch 214/500\n",
            "398/398 [==============================] - 0s 105us/step - loss: 0.1242 - acc: 0.9548 - val_loss: 0.2223 - val_acc: 0.9155\n",
            "Epoch 215/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1201 - acc: 0.9523 - val_loss: 0.3051 - val_acc: 0.9155\n",
            "Epoch 216/500\n",
            "398/398 [==============================] - 0s 105us/step - loss: 0.1452 - acc: 0.9347 - val_loss: 0.2050 - val_acc: 0.9296\n",
            "Epoch 217/500\n",
            "398/398 [==============================] - 0s 112us/step - loss: 0.1202 - acc: 0.9397 - val_loss: 0.1985 - val_acc: 0.9296\n",
            "Epoch 218/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1897 - acc: 0.9347 - val_loss: 0.2021 - val_acc: 0.9296\n",
            "Epoch 219/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.1544 - acc: 0.9322 - val_loss: 0.1605 - val_acc: 0.9296\n",
            "Epoch 220/500\n",
            "398/398 [==============================] - 0s 112us/step - loss: 0.1071 - acc: 0.9497 - val_loss: 0.2317 - val_acc: 0.9296\n",
            "Epoch 221/500\n",
            "398/398 [==============================] - 0s 115us/step - loss: 0.1354 - acc: 0.9548 - val_loss: 0.2283 - val_acc: 0.9296\n",
            "Epoch 222/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1131 - acc: 0.9397 - val_loss: 0.2064 - val_acc: 0.9155\n",
            "Epoch 223/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1251 - acc: 0.9523 - val_loss: 0.1654 - val_acc: 0.9155\n",
            "Epoch 224/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1268 - acc: 0.9523 - val_loss: 0.2278 - val_acc: 0.9296\n",
            "Epoch 225/500\n",
            "398/398 [==============================] - 0s 112us/step - loss: 0.1066 - acc: 0.9623 - val_loss: 0.2308 - val_acc: 0.9296\n",
            "Epoch 226/500\n",
            "398/398 [==============================] - 0s 122us/step - loss: 0.1084 - acc: 0.9472 - val_loss: 0.1788 - val_acc: 0.9155\n",
            "Epoch 227/500\n",
            "398/398 [==============================] - 0s 112us/step - loss: 0.1170 - acc: 0.9548 - val_loss: 0.1631 - val_acc: 0.9155\n",
            "Epoch 228/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1002 - acc: 0.9648 - val_loss: 0.3308 - val_acc: 0.9155\n",
            "Epoch 229/500\n",
            "398/398 [==============================] - 0s 153us/step - loss: 0.1251 - acc: 0.9472 - val_loss: 0.1516 - val_acc: 0.9296\n",
            "Epoch 230/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.1252 - acc: 0.9497 - val_loss: 0.2452 - val_acc: 0.9296\n",
            "Epoch 231/500\n",
            "398/398 [==============================] - 0s 112us/step - loss: 0.1126 - acc: 0.9598 - val_loss: 0.1724 - val_acc: 0.9155\n",
            "Epoch 232/500\n",
            "398/398 [==============================] - 0s 123us/step - loss: 0.1092 - acc: 0.9523 - val_loss: 0.2058 - val_acc: 0.9296\n",
            "Epoch 233/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1386 - acc: 0.9397 - val_loss: 0.2929 - val_acc: 0.9155\n",
            "Epoch 234/500\n",
            "398/398 [==============================] - 0s 114us/step - loss: 0.1154 - acc: 0.9472 - val_loss: 0.1740 - val_acc: 0.9155\n",
            "Epoch 235/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1152 - acc: 0.9497 - val_loss: 0.2473 - val_acc: 0.9296\n",
            "Epoch 236/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.0937 - acc: 0.9523 - val_loss: 0.2556 - val_acc: 0.9296\n",
            "Epoch 237/500\n",
            "398/398 [==============================] - 0s 104us/step - loss: 0.1329 - acc: 0.9372 - val_loss: 0.2140 - val_acc: 0.9296\n",
            "Epoch 238/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1147 - acc: 0.9523 - val_loss: 0.2320 - val_acc: 0.9296\n",
            "Epoch 239/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1139 - acc: 0.9598 - val_loss: 0.1856 - val_acc: 0.9296\n",
            "Epoch 240/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.0919 - acc: 0.9623 - val_loss: 0.1830 - val_acc: 0.9155\n",
            "Epoch 241/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1533 - acc: 0.9422 - val_loss: 0.1909 - val_acc: 0.9155\n",
            "Epoch 242/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1464 - acc: 0.9322 - val_loss: 0.1727 - val_acc: 0.9296\n",
            "Epoch 243/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.1089 - acc: 0.9497 - val_loss: 0.1866 - val_acc: 0.9296\n",
            "Epoch 244/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1015 - acc: 0.9648 - val_loss: 0.2157 - val_acc: 0.9014\n",
            "Epoch 245/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1879 - acc: 0.9246 - val_loss: 0.2108 - val_acc: 0.9014\n",
            "Epoch 246/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1266 - acc: 0.9548 - val_loss: 0.1746 - val_acc: 0.9296\n",
            "Epoch 247/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.1241 - acc: 0.9548 - val_loss: 0.1891 - val_acc: 0.9296\n",
            "Epoch 248/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1045 - acc: 0.9447 - val_loss: 0.1467 - val_acc: 0.9296\n",
            "Epoch 249/500\n",
            "398/398 [==============================] - 0s 112us/step - loss: 0.1123 - acc: 0.9573 - val_loss: 0.1756 - val_acc: 0.9155\n",
            "Epoch 250/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.0935 - acc: 0.9623 - val_loss: 0.2724 - val_acc: 0.9296\n",
            "Epoch 251/500\n",
            "398/398 [==============================] - 0s 112us/step - loss: 0.1122 - acc: 0.9673 - val_loss: 0.2430 - val_acc: 0.9296\n",
            "Epoch 252/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1337 - acc: 0.9472 - val_loss: 0.1510 - val_acc: 0.9437\n",
            "Epoch 253/500\n",
            "398/398 [==============================] - 0s 104us/step - loss: 0.1524 - acc: 0.9372 - val_loss: 0.1751 - val_acc: 0.9296\n",
            "Epoch 254/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1127 - acc: 0.9548 - val_loss: 0.1682 - val_acc: 0.9296\n",
            "Epoch 255/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1137 - acc: 0.9472 - val_loss: 0.1974 - val_acc: 0.9155\n",
            "Epoch 256/500\n",
            "398/398 [==============================] - 0s 126us/step - loss: 0.1566 - acc: 0.9397 - val_loss: 0.1573 - val_acc: 0.9296\n",
            "Epoch 257/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1478 - acc: 0.9347 - val_loss: 0.1882 - val_acc: 0.9296\n",
            "Epoch 258/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1022 - acc: 0.9497 - val_loss: 0.1891 - val_acc: 0.9296\n",
            "Epoch 259/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1065 - acc: 0.9548 - val_loss: 0.2143 - val_acc: 0.9155\n",
            "Epoch 260/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.0929 - acc: 0.9623 - val_loss: 0.1964 - val_acc: 0.9296\n",
            "Epoch 261/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.0971 - acc: 0.9472 - val_loss: 0.1791 - val_acc: 0.9296\n",
            "Epoch 262/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1449 - acc: 0.9523 - val_loss: 0.1619 - val_acc: 0.9296\n",
            "Epoch 263/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1133 - acc: 0.9472 - val_loss: 0.2105 - val_acc: 0.9155\n",
            "Epoch 264/500\n",
            "398/398 [==============================] - 0s 114us/step - loss: 0.1064 - acc: 0.9497 - val_loss: 0.1660 - val_acc: 0.9296\n",
            "Epoch 265/500\n",
            "398/398 [==============================] - 0s 143us/step - loss: 0.1329 - acc: 0.9472 - val_loss: 0.2781 - val_acc: 0.9296\n",
            "Epoch 266/500\n",
            "398/398 [==============================] - 0s 115us/step - loss: 0.1307 - acc: 0.9422 - val_loss: 0.1565 - val_acc: 0.9296\n",
            "Epoch 267/500\n",
            "398/398 [==============================] - 0s 118us/step - loss: 0.1242 - acc: 0.9548 - val_loss: 0.2246 - val_acc: 0.9296\n",
            "Epoch 268/500\n",
            "398/398 [==============================] - 0s 121us/step - loss: 0.1185 - acc: 0.9497 - val_loss: 0.1918 - val_acc: 0.9296\n",
            "Epoch 269/500\n",
            "398/398 [==============================] - 0s 101us/step - loss: 0.1417 - acc: 0.9497 - val_loss: 0.1490 - val_acc: 0.9437\n",
            "Epoch 270/500\n",
            "398/398 [==============================] - 0s 124us/step - loss: 0.1167 - acc: 0.9397 - val_loss: 0.2660 - val_acc: 0.9155\n",
            "Epoch 271/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.1134 - acc: 0.9447 - val_loss: 0.1720 - val_acc: 0.9296\n",
            "Epoch 272/500\n",
            "398/398 [==============================] - 0s 105us/step - loss: 0.1228 - acc: 0.9523 - val_loss: 0.1599 - val_acc: 0.9437\n",
            "Epoch 273/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1099 - acc: 0.9523 - val_loss: 0.1493 - val_acc: 0.9437\n",
            "Epoch 274/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1027 - acc: 0.9623 - val_loss: 0.2419 - val_acc: 0.9296\n",
            "Epoch 275/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1163 - acc: 0.9523 - val_loss: 0.2768 - val_acc: 0.9296\n",
            "Epoch 276/500\n",
            "398/398 [==============================] - 0s 102us/step - loss: 0.2300 - acc: 0.9171 - val_loss: 0.2233 - val_acc: 0.9014\n",
            "Epoch 277/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1327 - acc: 0.9523 - val_loss: 0.1739 - val_acc: 0.9296\n",
            "Epoch 278/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1123 - acc: 0.9447 - val_loss: 0.1627 - val_acc: 0.9155\n",
            "Epoch 279/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.1113 - acc: 0.9497 - val_loss: 0.1512 - val_acc: 0.9437\n",
            "Epoch 280/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1094 - acc: 0.9422 - val_loss: 0.1617 - val_acc: 0.9296\n",
            "Epoch 281/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1038 - acc: 0.9523 - val_loss: 0.1400 - val_acc: 0.9437\n",
            "Epoch 282/500\n",
            "398/398 [==============================] - 0s 112us/step - loss: 0.1194 - acc: 0.9497 - val_loss: 0.1805 - val_acc: 0.9296\n",
            "Epoch 283/500\n",
            "398/398 [==============================] - 0s 120us/step - loss: 0.1086 - acc: 0.9598 - val_loss: 0.1605 - val_acc: 0.9296\n",
            "Epoch 284/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1119 - acc: 0.9573 - val_loss: 0.2944 - val_acc: 0.9296\n",
            "Epoch 285/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.1272 - acc: 0.9623 - val_loss: 0.1835 - val_acc: 0.9296\n",
            "Epoch 286/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1192 - acc: 0.9573 - val_loss: 0.1523 - val_acc: 0.9296\n",
            "Epoch 287/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1093 - acc: 0.9497 - val_loss: 0.1745 - val_acc: 0.9296\n",
            "Epoch 288/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.1087 - acc: 0.9472 - val_loss: 0.1521 - val_acc: 0.9296\n",
            "Epoch 289/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.0906 - acc: 0.9648 - val_loss: 0.1636 - val_acc: 0.9296\n",
            "Epoch 290/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1052 - acc: 0.9623 - val_loss: 0.1738 - val_acc: 0.9296\n",
            "Epoch 291/500\n",
            "398/398 [==============================] - 0s 105us/step - loss: 0.0938 - acc: 0.9573 - val_loss: 0.1300 - val_acc: 0.9296\n",
            "Epoch 292/500\n",
            "398/398 [==============================] - 0s 104us/step - loss: 0.1122 - acc: 0.9573 - val_loss: 0.1535 - val_acc: 0.9296\n",
            "Epoch 293/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1031 - acc: 0.9548 - val_loss: 0.1658 - val_acc: 0.9296\n",
            "Epoch 294/500\n",
            "398/398 [==============================] - 0s 105us/step - loss: 0.0930 - acc: 0.9523 - val_loss: 0.1747 - val_acc: 0.9296\n",
            "Epoch 295/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1032 - acc: 0.9548 - val_loss: 0.1838 - val_acc: 0.9296\n",
            "Epoch 296/500\n",
            "398/398 [==============================] - 0s 105us/step - loss: 0.1033 - acc: 0.9648 - val_loss: 0.1575 - val_acc: 0.9437\n",
            "Epoch 297/500\n",
            "398/398 [==============================] - 0s 104us/step - loss: 0.1066 - acc: 0.9523 - val_loss: 0.1598 - val_acc: 0.9577\n",
            "Epoch 298/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1268 - acc: 0.9497 - val_loss: 0.1680 - val_acc: 0.9296\n",
            "Epoch 299/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1303 - acc: 0.9397 - val_loss: 0.1357 - val_acc: 0.9437\n",
            "Epoch 300/500\n",
            "398/398 [==============================] - 0s 103us/step - loss: 0.1415 - acc: 0.9573 - val_loss: 0.1507 - val_acc: 0.9437\n",
            "Epoch 301/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1901 - acc: 0.9146 - val_loss: 0.1627 - val_acc: 0.9437\n",
            "Epoch 302/500\n",
            "398/398 [==============================] - 0s 104us/step - loss: 0.1134 - acc: 0.9548 - val_loss: 0.1689 - val_acc: 0.9296\n",
            "Epoch 303/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1015 - acc: 0.9548 - val_loss: 0.1562 - val_acc: 0.9296\n",
            "Epoch 304/500\n",
            "398/398 [==============================] - 0s 112us/step - loss: 0.0969 - acc: 0.9523 - val_loss: 0.1659 - val_acc: 0.9437\n",
            "Epoch 305/500\n",
            "398/398 [==============================] - 0s 105us/step - loss: 0.1018 - acc: 0.9548 - val_loss: 0.3423 - val_acc: 0.9014\n",
            "Epoch 306/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1492 - acc: 0.9372 - val_loss: 0.1997 - val_acc: 0.9155\n",
            "Epoch 307/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.1093 - acc: 0.9573 - val_loss: 0.2036 - val_acc: 0.9296\n",
            "Epoch 308/500\n",
            "398/398 [==============================] - 0s 118us/step - loss: 0.0926 - acc: 0.9598 - val_loss: 0.2396 - val_acc: 0.9296\n",
            "Epoch 309/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.0866 - acc: 0.9673 - val_loss: 0.1628 - val_acc: 0.9296\n",
            "Epoch 310/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1001 - acc: 0.9573 - val_loss: 0.1791 - val_acc: 0.9296\n",
            "Epoch 311/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.0846 - acc: 0.9623 - val_loss: 0.1771 - val_acc: 0.9155\n",
            "Epoch 312/500\n",
            "398/398 [==============================] - 0s 104us/step - loss: 0.0995 - acc: 0.9648 - val_loss: 0.2122 - val_acc: 0.9296\n",
            "Epoch 313/500\n",
            "398/398 [==============================] - 0s 101us/step - loss: 0.1161 - acc: 0.9472 - val_loss: 0.1464 - val_acc: 0.9296\n",
            "Epoch 314/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1198 - acc: 0.9598 - val_loss: 0.1736 - val_acc: 0.9155\n",
            "Epoch 315/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1006 - acc: 0.9598 - val_loss: 0.1555 - val_acc: 0.9296\n",
            "Epoch 316/500\n",
            "398/398 [==============================] - 0s 102us/step - loss: 0.0900 - acc: 0.9573 - val_loss: 0.2273 - val_acc: 0.9296\n",
            "Epoch 317/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1059 - acc: 0.9497 - val_loss: 0.1705 - val_acc: 0.9296\n",
            "Epoch 318/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1092 - acc: 0.9523 - val_loss: 0.1493 - val_acc: 0.9437\n",
            "Epoch 319/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.1295 - acc: 0.9598 - val_loss: 0.1522 - val_acc: 0.9296\n",
            "Epoch 320/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1124 - acc: 0.9523 - val_loss: 0.1642 - val_acc: 0.9296\n",
            "Epoch 321/500\n",
            "398/398 [==============================] - 0s 105us/step - loss: 0.1074 - acc: 0.9548 - val_loss: 0.1938 - val_acc: 0.9296\n",
            "Epoch 322/500\n",
            "398/398 [==============================] - 0s 105us/step - loss: 0.1008 - acc: 0.9573 - val_loss: 0.1825 - val_acc: 0.9296\n",
            "Epoch 323/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1066 - acc: 0.9598 - val_loss: 0.1505 - val_acc: 0.9296\n",
            "Epoch 324/500\n",
            "398/398 [==============================] - 0s 105us/step - loss: 0.1072 - acc: 0.9548 - val_loss: 0.1476 - val_acc: 0.9437\n",
            "Epoch 325/500\n",
            "398/398 [==============================] - 0s 104us/step - loss: 0.1563 - acc: 0.9372 - val_loss: 0.1818 - val_acc: 0.9437\n",
            "Epoch 326/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1407 - acc: 0.9397 - val_loss: 0.2760 - val_acc: 0.9014\n",
            "Epoch 327/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1104 - acc: 0.9623 - val_loss: 0.2028 - val_acc: 0.9155\n",
            "Epoch 328/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.1113 - acc: 0.9447 - val_loss: 0.1675 - val_acc: 0.9296\n",
            "Epoch 329/500\n",
            "398/398 [==============================] - 0s 104us/step - loss: 0.1111 - acc: 0.9548 - val_loss: 0.1458 - val_acc: 0.9437\n",
            "Epoch 330/500\n",
            "398/398 [==============================] - 0s 102us/step - loss: 0.1182 - acc: 0.9523 - val_loss: 0.1691 - val_acc: 0.9296\n",
            "Epoch 331/500\n",
            "398/398 [==============================] - 0s 112us/step - loss: 0.1222 - acc: 0.9422 - val_loss: 0.1602 - val_acc: 0.9296\n",
            "Epoch 332/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.1028 - acc: 0.9523 - val_loss: 0.2300 - val_acc: 0.9296\n",
            "Epoch 333/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1144 - acc: 0.9472 - val_loss: 0.1347 - val_acc: 0.9437\n",
            "Epoch 334/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1043 - acc: 0.9548 - val_loss: 0.1626 - val_acc: 0.9296\n",
            "Epoch 335/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.0915 - acc: 0.9573 - val_loss: 0.2617 - val_acc: 0.9296\n",
            "Epoch 336/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1138 - acc: 0.9548 - val_loss: 0.1479 - val_acc: 0.9296\n",
            "Epoch 337/500\n",
            "398/398 [==============================] - 0s 105us/step - loss: 0.0913 - acc: 0.9623 - val_loss: 0.1983 - val_acc: 0.9296\n",
            "Epoch 338/500\n",
            "398/398 [==============================] - 0s 105us/step - loss: 0.0975 - acc: 0.9548 - val_loss: 0.1502 - val_acc: 0.9437\n",
            "Epoch 339/500\n",
            "398/398 [==============================] - 0s 117us/step - loss: 0.1062 - acc: 0.9573 - val_loss: 0.1421 - val_acc: 0.9437\n",
            "Epoch 340/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.0896 - acc: 0.9698 - val_loss: 0.1642 - val_acc: 0.9296\n",
            "Epoch 341/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.1033 - acc: 0.9648 - val_loss: 0.1497 - val_acc: 0.9437\n",
            "Epoch 342/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.0996 - acc: 0.9598 - val_loss: 0.2039 - val_acc: 0.9296\n",
            "Epoch 343/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.0911 - acc: 0.9698 - val_loss: 0.2164 - val_acc: 0.9014\n",
            "Epoch 344/500\n",
            "398/398 [==============================] - 0s 112us/step - loss: 0.1360 - acc: 0.9422 - val_loss: 0.1635 - val_acc: 0.9296\n",
            "Epoch 345/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.1206 - acc: 0.9372 - val_loss: 0.1471 - val_acc: 0.9437\n",
            "Epoch 346/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.1072 - acc: 0.9598 - val_loss: 0.2062 - val_acc: 0.9296\n",
            "Epoch 347/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.1118 - acc: 0.9523 - val_loss: 0.1637 - val_acc: 0.9296\n",
            "Epoch 348/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1066 - acc: 0.9573 - val_loss: 0.1767 - val_acc: 0.9296\n",
            "Epoch 349/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.0930 - acc: 0.9598 - val_loss: 0.2141 - val_acc: 0.9296\n",
            "Epoch 350/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1169 - acc: 0.9523 - val_loss: 0.3740 - val_acc: 0.9014\n",
            "Epoch 351/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1323 - acc: 0.9447 - val_loss: 0.2003 - val_acc: 0.9296\n",
            "Epoch 352/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1078 - acc: 0.9573 - val_loss: 0.2009 - val_acc: 0.9296\n",
            "Epoch 353/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1098 - acc: 0.9497 - val_loss: 0.1688 - val_acc: 0.9296\n",
            "Epoch 354/500\n",
            "398/398 [==============================] - 0s 115us/step - loss: 0.1043 - acc: 0.9548 - val_loss: 0.1554 - val_acc: 0.9296\n",
            "Epoch 355/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.0998 - acc: 0.9598 - val_loss: 0.1480 - val_acc: 0.9437\n",
            "Epoch 356/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1203 - acc: 0.9573 - val_loss: 0.1555 - val_acc: 0.9296\n",
            "Epoch 357/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.1007 - acc: 0.9598 - val_loss: 0.1888 - val_acc: 0.9296\n",
            "Epoch 358/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.0989 - acc: 0.9523 - val_loss: 0.1435 - val_acc: 0.9437\n",
            "Epoch 359/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.0862 - acc: 0.9623 - val_loss: 0.2592 - val_acc: 0.9296\n",
            "Epoch 360/500\n",
            "398/398 [==============================] - 0s 103us/step - loss: 0.1166 - acc: 0.9523 - val_loss: 0.1367 - val_acc: 0.9437\n",
            "Epoch 361/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1046 - acc: 0.9497 - val_loss: 0.1417 - val_acc: 0.9437\n",
            "Epoch 362/500\n",
            "398/398 [==============================] - 0s 118us/step - loss: 0.1088 - acc: 0.9422 - val_loss: 0.1395 - val_acc: 0.9437\n",
            "Epoch 363/500\n",
            "398/398 [==============================] - 0s 123us/step - loss: 0.1128 - acc: 0.9648 - val_loss: 0.1408 - val_acc: 0.9437\n",
            "Epoch 364/500\n",
            "398/398 [==============================] - 0s 102us/step - loss: 0.1051 - acc: 0.9548 - val_loss: 0.1746 - val_acc: 0.9296\n",
            "Epoch 365/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.0837 - acc: 0.9673 - val_loss: 0.2153 - val_acc: 0.9296\n",
            "Epoch 366/500\n",
            "398/398 [==============================] - 0s 103us/step - loss: 0.0994 - acc: 0.9623 - val_loss: 0.1394 - val_acc: 0.9296\n",
            "Epoch 367/500\n",
            "398/398 [==============================] - 0s 105us/step - loss: 0.1000 - acc: 0.9548 - val_loss: 0.2456 - val_acc: 0.9296\n",
            "Epoch 368/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.0939 - acc: 0.9573 - val_loss: 0.1362 - val_acc: 0.9437\n",
            "Epoch 369/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.0964 - acc: 0.9573 - val_loss: 0.1746 - val_acc: 0.9296\n",
            "Epoch 370/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1015 - acc: 0.9548 - val_loss: 0.2271 - val_acc: 0.9296\n",
            "Epoch 371/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.0941 - acc: 0.9623 - val_loss: 0.2319 - val_acc: 0.9296\n",
            "Epoch 372/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1409 - acc: 0.9372 - val_loss: 0.2637 - val_acc: 0.9296\n",
            "Epoch 373/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1275 - acc: 0.9497 - val_loss: 0.1672 - val_acc: 0.9296\n",
            "Epoch 374/500\n",
            "398/398 [==============================] - 0s 100us/step - loss: 0.1115 - acc: 0.9598 - val_loss: 0.1469 - val_acc: 0.9296\n",
            "Epoch 375/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.0971 - acc: 0.9523 - val_loss: 0.1711 - val_acc: 0.9296\n",
            "Epoch 376/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.0974 - acc: 0.9673 - val_loss: 0.2245 - val_acc: 0.9296\n",
            "Epoch 377/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1069 - acc: 0.9548 - val_loss: 0.1330 - val_acc: 0.9437\n",
            "Epoch 378/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.0885 - acc: 0.9673 - val_loss: 0.1970 - val_acc: 0.9296\n",
            "Epoch 379/500\n",
            "398/398 [==============================] - 0s 115us/step - loss: 0.1096 - acc: 0.9598 - val_loss: 0.1608 - val_acc: 0.9296\n",
            "Epoch 380/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.1186 - acc: 0.9623 - val_loss: 0.1744 - val_acc: 0.9296\n",
            "Epoch 381/500\n",
            "398/398 [==============================] - 0s 105us/step - loss: 0.1392 - acc: 0.9573 - val_loss: 0.1377 - val_acc: 0.9437\n",
            "Epoch 382/500\n",
            "398/398 [==============================] - 0s 105us/step - loss: 0.0934 - acc: 0.9623 - val_loss: 0.2371 - val_acc: 0.9155\n",
            "Epoch 383/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1168 - acc: 0.9523 - val_loss: 0.1472 - val_acc: 0.9437\n",
            "Epoch 384/500\n",
            "398/398 [==============================] - 0s 104us/step - loss: 0.1367 - acc: 0.9347 - val_loss: 0.1643 - val_acc: 0.9296\n",
            "Epoch 385/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1083 - acc: 0.9573 - val_loss: 0.1356 - val_acc: 0.9437\n",
            "Epoch 386/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1297 - acc: 0.9397 - val_loss: 0.1463 - val_acc: 0.9437\n",
            "Epoch 387/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1157 - acc: 0.9573 - val_loss: 0.1551 - val_acc: 0.9296\n",
            "Epoch 388/500\n",
            "398/398 [==============================] - 0s 103us/step - loss: 0.1188 - acc: 0.9422 - val_loss: 0.2048 - val_acc: 0.9296\n",
            "Epoch 389/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1053 - acc: 0.9673 - val_loss: 0.1540 - val_acc: 0.9296\n",
            "Epoch 390/500\n",
            "398/398 [==============================] - 0s 122us/step - loss: 0.1031 - acc: 0.9598 - val_loss: 0.1396 - val_acc: 0.9437\n",
            "Epoch 391/500\n",
            "398/398 [==============================] - 0s 105us/step - loss: 0.1079 - acc: 0.9573 - val_loss: 0.2920 - val_acc: 0.9296\n",
            "Epoch 392/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1110 - acc: 0.9573 - val_loss: 0.1613 - val_acc: 0.9296\n",
            "Epoch 393/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1027 - acc: 0.9598 - val_loss: 0.1812 - val_acc: 0.9296\n",
            "Epoch 394/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1152 - acc: 0.9497 - val_loss: 0.2010 - val_acc: 0.9155\n",
            "Epoch 395/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1312 - acc: 0.9422 - val_loss: 0.1672 - val_acc: 0.9296\n",
            "Epoch 396/500\n",
            "398/398 [==============================] - 0s 102us/step - loss: 0.1026 - acc: 0.9548 - val_loss: 0.1763 - val_acc: 0.9437\n",
            "Epoch 397/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.1183 - acc: 0.9548 - val_loss: 0.1383 - val_acc: 0.9437\n",
            "Epoch 398/500\n",
            "398/398 [==============================] - 0s 112us/step - loss: 0.1199 - acc: 0.9598 - val_loss: 0.1926 - val_acc: 0.9296\n",
            "Epoch 399/500\n",
            "398/398 [==============================] - 0s 104us/step - loss: 0.0924 - acc: 0.9673 - val_loss: 0.1722 - val_acc: 0.9296\n",
            "Epoch 400/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.0976 - acc: 0.9548 - val_loss: 0.1304 - val_acc: 0.9437\n",
            "Epoch 401/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1430 - acc: 0.9347 - val_loss: 0.1431 - val_acc: 0.9437\n",
            "Epoch 402/500\n",
            "398/398 [==============================] - 0s 117us/step - loss: 0.1283 - acc: 0.9523 - val_loss: 0.1746 - val_acc: 0.9296\n",
            "Epoch 403/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1129 - acc: 0.9573 - val_loss: 0.1603 - val_acc: 0.9296\n",
            "Epoch 404/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1181 - acc: 0.9548 - val_loss: 0.1586 - val_acc: 0.9296\n",
            "Epoch 405/500\n",
            "398/398 [==============================] - 0s 115us/step - loss: 0.1008 - acc: 0.9497 - val_loss: 0.1515 - val_acc: 0.9296\n",
            "Epoch 406/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.0880 - acc: 0.9673 - val_loss: 0.2129 - val_acc: 0.9155\n",
            "Epoch 407/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.0864 - acc: 0.9623 - val_loss: 0.1544 - val_acc: 0.9296\n",
            "Epoch 408/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1475 - acc: 0.9397 - val_loss: 0.1353 - val_acc: 0.9296\n",
            "Epoch 409/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1154 - acc: 0.9523 - val_loss: 0.1292 - val_acc: 0.9437\n",
            "Epoch 410/500\n",
            "398/398 [==============================] - 0s 104us/step - loss: 0.1151 - acc: 0.9673 - val_loss: 0.1393 - val_acc: 0.9577\n",
            "Epoch 411/500\n",
            "398/398 [==============================] - 0s 128us/step - loss: 0.1025 - acc: 0.9573 - val_loss: 0.1542 - val_acc: 0.9296\n",
            "Epoch 412/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.1178 - acc: 0.9422 - val_loss: 0.1637 - val_acc: 0.9296\n",
            "Epoch 413/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.1481 - acc: 0.9422 - val_loss: 0.1940 - val_acc: 0.9014\n",
            "Epoch 414/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1012 - acc: 0.9573 - val_loss: 0.1680 - val_acc: 0.9296\n",
            "Epoch 415/500\n",
            "398/398 [==============================] - 0s 118us/step - loss: 0.0885 - acc: 0.9523 - val_loss: 0.1333 - val_acc: 0.9437\n",
            "Epoch 416/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.0918 - acc: 0.9673 - val_loss: 0.2259 - val_acc: 0.9296\n",
            "Epoch 417/500\n",
            "398/398 [==============================] - 0s 104us/step - loss: 0.1174 - acc: 0.9548 - val_loss: 0.2086 - val_acc: 0.9296\n",
            "Epoch 418/500\n",
            "398/398 [==============================] - 0s 105us/step - loss: 0.0860 - acc: 0.9673 - val_loss: 0.1980 - val_acc: 0.9296\n",
            "Epoch 419/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.0918 - acc: 0.9598 - val_loss: 0.1385 - val_acc: 0.9437\n",
            "Epoch 420/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.0891 - acc: 0.9623 - val_loss: 0.1928 - val_acc: 0.9296\n",
            "Epoch 421/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1016 - acc: 0.9598 - val_loss: 0.1256 - val_acc: 0.9577\n",
            "Epoch 422/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1108 - acc: 0.9548 - val_loss: 0.1435 - val_acc: 0.9296\n",
            "Epoch 423/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.0907 - acc: 0.9648 - val_loss: 0.2349 - val_acc: 0.9296\n",
            "Epoch 424/500\n",
            "398/398 [==============================] - 0s 115us/step - loss: 0.0922 - acc: 0.9573 - val_loss: 0.1579 - val_acc: 0.9437\n",
            "Epoch 425/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.0845 - acc: 0.9648 - val_loss: 0.1653 - val_acc: 0.9155\n",
            "Epoch 426/500\n",
            "398/398 [==============================] - 0s 114us/step - loss: 0.1303 - acc: 0.9497 - val_loss: 0.1370 - val_acc: 0.9296\n",
            "Epoch 427/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.0942 - acc: 0.9573 - val_loss: 0.1471 - val_acc: 0.9296\n",
            "Epoch 428/500\n",
            "398/398 [==============================] - 0s 104us/step - loss: 0.0852 - acc: 0.9598 - val_loss: 0.1978 - val_acc: 0.9296\n",
            "Epoch 429/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.0858 - acc: 0.9673 - val_loss: 0.1941 - val_acc: 0.9296\n",
            "Epoch 430/500\n",
            "398/398 [==============================] - 0s 102us/step - loss: 0.1034 - acc: 0.9523 - val_loss: 0.1966 - val_acc: 0.9296\n",
            "Epoch 431/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1096 - acc: 0.9598 - val_loss: 0.1816 - val_acc: 0.9296\n",
            "Epoch 432/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1175 - acc: 0.9523 - val_loss: 0.1679 - val_acc: 0.9296\n",
            "Epoch 433/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.0921 - acc: 0.9548 - val_loss: 0.1401 - val_acc: 0.9437\n",
            "Epoch 434/500\n",
            "398/398 [==============================] - 0s 116us/step - loss: 0.1089 - acc: 0.9523 - val_loss: 0.1477 - val_acc: 0.9437\n",
            "Epoch 435/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.0815 - acc: 0.9648 - val_loss: 0.1573 - val_acc: 0.9437\n",
            "Epoch 436/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.0866 - acc: 0.9673 - val_loss: 0.2743 - val_acc: 0.9296\n",
            "Epoch 437/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1018 - acc: 0.9598 - val_loss: 0.1622 - val_acc: 0.9296\n",
            "Epoch 438/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.0948 - acc: 0.9724 - val_loss: 0.1716 - val_acc: 0.9296\n",
            "Epoch 439/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1114 - acc: 0.9648 - val_loss: 0.1632 - val_acc: 0.9296\n",
            "Epoch 440/500\n",
            "398/398 [==============================] - 0s 105us/step - loss: 0.1328 - acc: 0.9548 - val_loss: 0.1374 - val_acc: 0.9577\n",
            "Epoch 441/500\n",
            "398/398 [==============================] - 0s 118us/step - loss: 0.0858 - acc: 0.9623 - val_loss: 0.1544 - val_acc: 0.9437\n",
            "Epoch 442/500\n",
            "398/398 [==============================] - 0s 112us/step - loss: 0.0681 - acc: 0.9749 - val_loss: 0.3215 - val_acc: 0.9296\n",
            "Epoch 443/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1224 - acc: 0.9523 - val_loss: 0.1416 - val_acc: 0.9296\n",
            "Epoch 444/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.1035 - acc: 0.9548 - val_loss: 0.1492 - val_acc: 0.9437\n",
            "Epoch 445/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1095 - acc: 0.9548 - val_loss: 0.1909 - val_acc: 0.9296\n",
            "Epoch 446/500\n",
            "398/398 [==============================] - 0s 113us/step - loss: 0.0807 - acc: 0.9673 - val_loss: 0.1543 - val_acc: 0.9577\n",
            "Epoch 447/500\n",
            "398/398 [==============================] - 0s 105us/step - loss: 0.0884 - acc: 0.9623 - val_loss: 0.1578 - val_acc: 0.9437\n",
            "Epoch 448/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.0878 - acc: 0.9648 - val_loss: 0.1378 - val_acc: 0.9437\n",
            "Epoch 449/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1026 - acc: 0.9648 - val_loss: 0.1970 - val_acc: 0.9296\n",
            "Epoch 450/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.0973 - acc: 0.9573 - val_loss: 0.1386 - val_acc: 0.9437\n",
            "Epoch 451/500\n",
            "398/398 [==============================] - 0s 120us/step - loss: 0.0900 - acc: 0.9497 - val_loss: 0.2499 - val_acc: 0.9296\n",
            "Epoch 452/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1043 - acc: 0.9623 - val_loss: 0.1741 - val_acc: 0.9296\n",
            "Epoch 453/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.0947 - acc: 0.9523 - val_loss: 0.2303 - val_acc: 0.9296\n",
            "Epoch 454/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.0962 - acc: 0.9623 - val_loss: 0.1704 - val_acc: 0.9437\n",
            "Epoch 455/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.0876 - acc: 0.9548 - val_loss: 0.1290 - val_acc: 0.9296\n",
            "Epoch 456/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1166 - acc: 0.9598 - val_loss: 0.1946 - val_acc: 0.9296\n",
            "Epoch 457/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.0795 - acc: 0.9648 - val_loss: 0.1436 - val_acc: 0.9577\n",
            "Epoch 458/500\n",
            "398/398 [==============================] - 0s 112us/step - loss: 0.1071 - acc: 0.9523 - val_loss: 0.1359 - val_acc: 0.9296\n",
            "Epoch 459/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1460 - acc: 0.9472 - val_loss: 0.2018 - val_acc: 0.9155\n",
            "Epoch 460/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1193 - acc: 0.9523 - val_loss: 0.1757 - val_acc: 0.9155\n",
            "Epoch 461/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.0987 - acc: 0.9548 - val_loss: 0.1589 - val_acc: 0.9296\n",
            "Epoch 462/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.0946 - acc: 0.9623 - val_loss: 0.1815 - val_acc: 0.9296\n",
            "Epoch 463/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1129 - acc: 0.9472 - val_loss: 0.1252 - val_acc: 0.9296\n",
            "Epoch 464/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.0930 - acc: 0.9548 - val_loss: 0.3651 - val_acc: 0.9014\n",
            "Epoch 465/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1304 - acc: 0.9623 - val_loss: 0.1506 - val_acc: 0.9437\n",
            "Epoch 466/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1080 - acc: 0.9598 - val_loss: 0.1539 - val_acc: 0.9437\n",
            "Epoch 467/500\n",
            "398/398 [==============================] - 0s 104us/step - loss: 0.1098 - acc: 0.9523 - val_loss: 0.1591 - val_acc: 0.9296\n",
            "Epoch 468/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1040 - acc: 0.9523 - val_loss: 0.1363 - val_acc: 0.9437\n",
            "Epoch 469/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.0940 - acc: 0.9648 - val_loss: 0.1658 - val_acc: 0.9437\n",
            "Epoch 470/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.1006 - acc: 0.9623 - val_loss: 0.1415 - val_acc: 0.9577\n",
            "Epoch 471/500\n",
            "398/398 [==============================] - 0s 116us/step - loss: 0.1189 - acc: 0.9472 - val_loss: 0.1863 - val_acc: 0.9296\n",
            "Epoch 472/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.0968 - acc: 0.9573 - val_loss: 0.1417 - val_acc: 0.9296\n",
            "Epoch 473/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.0943 - acc: 0.9698 - val_loss: 0.1873 - val_acc: 0.9296\n",
            "Epoch 474/500\n",
            "398/398 [==============================] - 0s 100us/step - loss: 0.1021 - acc: 0.9523 - val_loss: 0.1463 - val_acc: 0.9577\n",
            "Epoch 475/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.0948 - acc: 0.9623 - val_loss: 0.1793 - val_acc: 0.9296\n",
            "Epoch 476/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.1008 - acc: 0.9673 - val_loss: 0.2360 - val_acc: 0.9296\n",
            "Epoch 477/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.0982 - acc: 0.9673 - val_loss: 0.1292 - val_acc: 0.9437\n",
            "Epoch 478/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.0940 - acc: 0.9648 - val_loss: 0.1624 - val_acc: 0.9296\n",
            "Epoch 479/500\n",
            "398/398 [==============================] - 0s 103us/step - loss: 0.1179 - acc: 0.9548 - val_loss: 0.1535 - val_acc: 0.9296\n",
            "Epoch 480/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.0861 - acc: 0.9648 - val_loss: 0.1399 - val_acc: 0.9437\n",
            "Epoch 481/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.0796 - acc: 0.9623 - val_loss: 0.1560 - val_acc: 0.9437\n",
            "Epoch 482/500\n",
            "398/398 [==============================] - 0s 114us/step - loss: 0.1344 - acc: 0.9246 - val_loss: 0.1346 - val_acc: 0.9437\n",
            "Epoch 483/500\n",
            "398/398 [==============================] - 0s 106us/step - loss: 0.1468 - acc: 0.9573 - val_loss: 0.1346 - val_acc: 0.9577\n",
            "Epoch 484/500\n",
            "398/398 [==============================] - 0s 102us/step - loss: 0.0881 - acc: 0.9648 - val_loss: 0.1572 - val_acc: 0.9296\n",
            "Epoch 485/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.0858 - acc: 0.9623 - val_loss: 0.1300 - val_acc: 0.9437\n",
            "Epoch 486/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1098 - acc: 0.9673 - val_loss: 0.1305 - val_acc: 0.9577\n",
            "Epoch 487/500\n",
            "398/398 [==============================] - 0s 107us/step - loss: 0.0827 - acc: 0.9724 - val_loss: 0.2557 - val_acc: 0.9155\n",
            "Epoch 488/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1224 - acc: 0.9472 - val_loss: 0.2576 - val_acc: 0.9014\n",
            "Epoch 489/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1369 - acc: 0.9472 - val_loss: 0.2250 - val_acc: 0.9296\n",
            "Epoch 490/500\n",
            "398/398 [==============================] - 0s 108us/step - loss: 0.1017 - acc: 0.9548 - val_loss: 0.1807 - val_acc: 0.9296\n",
            "Epoch 491/500\n",
            "398/398 [==============================] - 0s 118us/step - loss: 0.1044 - acc: 0.9548 - val_loss: 0.1436 - val_acc: 0.9296\n",
            "Epoch 492/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.1046 - acc: 0.9573 - val_loss: 0.1712 - val_acc: 0.9296\n",
            "Epoch 493/500\n",
            "398/398 [==============================] - 0s 121us/step - loss: 0.1082 - acc: 0.9497 - val_loss: 0.1503 - val_acc: 0.9296\n",
            "Epoch 494/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.0933 - acc: 0.9598 - val_loss: 0.1309 - val_acc: 0.9437\n",
            "Epoch 495/500\n",
            "398/398 [==============================] - 0s 111us/step - loss: 0.0894 - acc: 0.9598 - val_loss: 0.1518 - val_acc: 0.9437\n",
            "Epoch 496/500\n",
            "398/398 [==============================] - 0s 116us/step - loss: 0.0876 - acc: 0.9724 - val_loss: 0.1428 - val_acc: 0.9296\n",
            "Epoch 497/500\n",
            "398/398 [==============================] - 0s 110us/step - loss: 0.0827 - acc: 0.9648 - val_loss: 0.2045 - val_acc: 0.9437\n",
            "Epoch 498/500\n",
            "398/398 [==============================] - 0s 112us/step - loss: 0.1050 - acc: 0.9573 - val_loss: 0.1790 - val_acc: 0.9296\n",
            "Epoch 499/500\n",
            "398/398 [==============================] - 0s 109us/step - loss: 0.1208 - acc: 0.9472 - val_loss: 0.1641 - val_acc: 0.9296\n",
            "Epoch 500/500\n",
            "398/398 [==============================] - 0s 104us/step - loss: 0.0814 - acc: 0.9673 - val_loss: 0.1858 - val_acc: 0.9296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLe6qemayUY4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "4f3e8378-c738-4207-8c2f-cbcadc0b0384"
      },
      "source": [
        "# Part 3 - Making predictions and evaluating the model\n",
        "\n",
        "# Predicting the Test set results\n",
        "ann_pred = classifier.predict(X_test)\n",
        "ann_pred = (ann_pred > 0.5)\n",
        "\n",
        "#Model Evaluation\n",
        "ann = accuracy_score(Y_test, ann_pred)\n",
        "print('Accuracy Score: ' + str(ann))\n",
        "\n",
        "print('Precision Score: ' + str(precision_score(Y_test, ann_pred)))\n",
        "\n",
        "print('Recall Score: ' + str(recall_score(Y_test, ann_pred)))\n",
        "\n",
        "print('F1 Score: ' + str(f1_score(Y_test, ann_pred)))\n",
        "\n",
        "print('Classification Report: \\n' + str(classification_report(Y_test, ann_pred)))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score: 0.95\n",
            "Precision Score: 0.95\n",
            "Recall Score: 0.9661016949152542\n",
            "F1 Score: 0.957983193277311\n",
            "Classification Report: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.93      0.94        41\n",
            "           1       0.95      0.97      0.96        59\n",
            "\n",
            "    accuracy                           0.95       100\n",
            "   macro avg       0.95      0.95      0.95       100\n",
            "weighted avg       0.95      0.95      0.95       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4emSDq8x8NE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "8b8cbb1a-a1f6-427c-d518-aad7deb81c23"
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEaCAYAAAAL7cBuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEaCAYAAAAL7cBuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUB5ukyvvYUi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "839744e7-f8a5-41ce-bec2-5e493cda6422"
      },
      "source": [
        "print('\\n                             Accuracy')\n",
        "print('                            -------------')\n",
        "\n",
        "print('Logistic Regression        : {:.04} %'.format(logits_acc * 100))\n",
        "print('KNN Classifier             : {:.04} %'.format(kacc * 100))\n",
        "print('Linear SVC                 : {:.04} %'.format(lsvcacc * 100))\n",
        "print('Gaussian Kernel SVC        : {:.04} %'.format(ksvcaccacc * 100))\n",
        "print('Decision Trees Classifier  : {:.04} %'.format(dtacc * 100))\n",
        "print('Random Forest Classifier   : {:.04} %'.format(rmacc * 100))\n",
        "print('BernoulliNB Classifier     : {:.04} %'.format(bncacc * 100))\n",
        "print('MultinomialNB Classifier   : {:.04} %'.format(mulacc * 100))\n",
        "print('Artificial Neural Network  : {:.04} %'.format(ann * 100))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "                             Accuracy\n",
            "                            -------------\n",
            "Logistic Regression        : 95.0 %\n",
            "KNN Classifier             : 94.0 %\n",
            "Linear SVC                 : 95.0 %\n",
            "Gaussian Kernel SVC        : 59.0 %\n",
            "Decision Trees Classifier  : 90.0 %\n",
            "Random Forest Classifier   : 96.0 %\n",
            "BernoulliNB Classifier     : 59.0 %\n",
            "MultinomialNB Classifier   : 90.0 %\n",
            "Artificial Neural Network  : 95.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgfdbksqvlXW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "outputId": "43b18e05-33e4-4d1e-8eff-f00f4bf01b4a"
      },
      "source": [
        "figure = plt.figure(figsize=(15, 10))\n",
        "# Visualizing the results\n",
        "objects = ['Logistic Regression',\n",
        "           'KNN', \n",
        "           'Linear SVC', \n",
        "           'Gaussian SVC', \n",
        "           'Decision Trees', \n",
        "           'Random Forest', \n",
        "           'BernoulliNB', \n",
        "           'MultinomialNB',\n",
        "           'Artificial Neural Network']\n",
        "y_pos = np.arange(len(objects))\n",
        "plt.bar(y_pos,[logits_acc,kacc,lsvcacc,ksvcaccacc,dtacc,rmacc,bncacc,mulacc, ann],alpha=0.5)\n",
        "plt.xticks(y_pos,objects)\n",
        "plt.ylabel('Number')\n",
        "plt.title('Accuracy Comparism')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Accuracy Comparism')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA34AAAJQCAYAAADR+LbmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3XuY3fO99//XJJODJBKZSSSCRk1Q\ntCmROqRKSIpqm9u+N6JFadhoVGn9aJ1Kdh2ytcrlXESqDntHW9xatyI0jYoiIo7tTRLuCtFIRuMQ\nOUxmfn/0Z36mCYbMmsz+eDyuy3VZa32z1nves6zM0zpMVVNTU1MAAAAoVqd1PQAAAACVJfwAAAAK\nJ/wAAAAKJ/wAAAAKJ/wAAAAKJ/wAAAAKJ/wAgCRJVVVVbrjhhnU9BgAVIPwAWKOXXnop3bp1y6BB\ng9LQ0LCux+kwbrjhhuy2227p06dPevbsmU9/+tM5+eST89JLL63r0dbaggULsv/++6/rMQCoAOEH\nwBpNmjQpX/nKV7LBBhvkN7/5zboeJ0myYsWKdXr7RxxxRI444ojstttuufPOO/PMM8/k4osvziuv\nvJILLrhgnc62Nt7Z68CBA9O9e/d1PA0AlSD8AFhNY2NjJk2alMMPPzyHHXZYrrrqqtWOaWhoyIQJ\nE1JXV5du3bpl4403znHHHdd8+ZtvvpkTTjghm266abp165bNNtss5557bpLkhRdeSFVVVf74xz+2\nuM4hQ4bkrLPOaj5dVVWViy++OF//+tfTp0+fHHrooUmS0047LVtvvXV69OiRTTfdNMccc0yWLFnS\n4roeffTR7LPPPundu3d69eqVHXfcMQ899FDmzZuXTp06ZcaMGS2Onz59ejp37pz/+3//7xp38utf\n/zrXXnttrrvuupx99tkZMWJEBg8enD333DO/+MUvcsYZZzQf+7//9//ODjvskG7dumXDDTfM+PHj\n89ZbbzVffvjhh2f06NG55JJLsskmm6RXr1458sgjs3Llylx55ZUZPHhw+vbtm6OOOqpF7I4cOTLj\nxo3LD37wg/Tr1y+9e/fOUUcdlWXLljUfc88992TkyJGpqalJnz59svvuu+fhhx9u8bW8117/+aWe\n11xzTbbeeut07949NTU12W233TJ//vwkyc9//vNUV1fn97//fT7zmc9kvfXWy8iRI/Pyyy9n+vTp\n2X777dOzZ8+MHj26iGdDAf67q17XAwDQ8dx5551Zvnx5vvSlL2WHHXbIGWeckRdeeCGbbbZZ8zFH\nHHFE7rzzzlxwwQUZMWJEXn311Tz44INJkqampnzlK1/JX//611xyySUZOnRo5s+fn//zf/7Ph55l\nwoQJmTBhQn70ox+lsbExSbLeeuvlqquuyqabbpq5c+fm2GOPzXe+851cd911SZKnn346u+22W8aM\nGZP77rsvffr0ycyZM9PY2JjNN988X/ziF3P11VdnxIgRzbdz9dVXZ6+99srgwYPXOMf111+fIUOG\n5KCDDlrj5X379k2SPPHEExkzZkyOO+643HjjjXn++edz9NFH54033sj111/ffPzDDz+cjTfeOPfc\nc0/mzJmTAw44IC+99FL69++f3/3ud5k3b17233//bL/99vnWt77V/Od+9atfZezYsbn//vszZ86c\nHHHEEenZs2cuvPDCJP8I7vHjx+ezn/1sGhoacuGFF2afffbJc889l9ra2vfd67s9+uijOeaYY3Lt\ntddm9913z+uvv56HHnqoxTGNjY2ZMGFCrrnmmnTp0iVjx47N2LFj07lz51xxxRXp3r17DjrooHzv\ne9/LlClT3vubDEDlNQHAPxkzZkzT9773vebTe++9d9Npp53WfPq5555rStL0y1/+co1/furUqU1J\nmh555JE1Xv788883JWm6//77W5xfV1fXdOaZZzafTtI0bty4D5z3lltuaeratWvTqlWrmpqampoO\nOeSQpqFDhzaf/me//vWvm3r06NG0ZMmSpqampqbXXnutab311mu65ZZb3vM2tt5666avfvWrHzjL\nIYcc0vS5z32uxXm33XZbU1VVVdMLL7zQ1NTU1HTYYYc19e/fv2n58uXNx+y7775NtbW1TcuWLWs+\nb8yYMU3/+q//2nx69913bxo8eHBTQ0ND83k/+9nPmrp169b05ptvrnGeVatWNW2wwQZNN9xwQ/N5\n77XXJE3XX399U1PTP3bau3fv5h39s8mTJzclaXrssceazzv//PObkjTNnDmz+byf/vSnTbW1tWu8\nDgDaj5d6AtDCSy+9lDvuuCOHH35483mHHXZYrr322uYPeZk1a1aSZK+99lrjdTz66KPp27dvhg8f\nvtbz7Ljjjqudd8stt2S33XbLoEGD0qtXrxx88MFZsWJFXnnllebbHzVqVDp1WvNfc2PGjEmfPn1y\n4403JvnHB7b06dMnX/3qV99zjqamplbN+86zje+2++67p6mpKc8880zzeVtvvXW6du3afHrgwIHZ\naqut0q1btxbnLVy4sMV17bjjjuncuXPz6c9//vNZvnx55s6dmyR5/vnnc+ihh2bIkCHp3bt3evfu\nnSVLlqz2EtY17fXdvvjFL2bzzTfPJz/5yRx00EG56qqrsmjRohbHVFVV5TOf+UyLeZNk6NChLc5b\nvHhxVq1a9b63B0BlCT8AWpg0aVJWrVqV7bffPtXV1amurs6hhx6aBQsWtNmHvLwTZP8cUytXrlzt\n2J49e7Y4/dBDD+WAAw7IbrvtlltvvTWzZs3KlVdemaT1H/5SXV2dI444IldffXWSf7yX7Zvf/Gaq\nq9/7HRBbbbVV/vznP7fq+lujS5cuLU5XVVWt8bw1vQzz/bzzEtvLLrssf/rTnzJ79uxsuOGGq+3m\nn/f6z3r16pWZM2fm1ltvzZZbbpkrr7wyQ4YMyaOPPtp8TKdOnVpEaFVV1Wpf2zvntTacAagM4QdA\ns3c+1OXUU0/N7NmzW/zzta99rflDXoYNG5Ykufvuu9d4PTvssENee+21zJw5c42X9+/fP0ny8ssv\nN5+3cOHCVn0IyB//+Mf069cvZ599dnbaaadsueWWzR848u7bv/fee983mo488sg8/vjjufLKK/PE\nE0/kyCOPfN/bPeSQQzJnzpz813/91xovf+2115Ik2267baZPn97isj/84Q+pqqrKtttu+4Ff3wd5\n5JFHWjx7NmPGjHTr1i11dXVZvHhxnnnmmfzgBz/I3nvvnW222Sbdu3df7VnD1urcuXN22223/Pu/\n/3seffTRbLTRRrnpppvW+msAoP35cBcAmt1555158cUXc/TRR+cTn/hEi8sOP/zwfOlLX8oLL7yQ\nIUOG5OCDD8748eOzbNmy7LLLLqmvr8+MGTNy/PHHZ88998wXvvCFjB07Nj/96U8zdOjQvPzyy/nz\nn/+cI488Muutt14+//nP5/zzz8+nPvWpNDQ05LTTTmvxMsf3stVWW+XVV1/NpEmTsscee+SPf/xj\nLr/88hbHnHzyydlpp51y8MEH58QTT0zfvn0za9asbLLJJtlll12SJIMHD84+++yT448/PqNGjcrm\nm2/+vre7//775xvf+EYOO+ywPP3009l3332z8cYb5/nnn8/Pf/7z9O3bNz/96U9z0kknZdiwYfnu\nd7+bo48+Oi+88EKOO+64HHzwwavt9KNYvHhxjj322Bx//PGZN29ezjjjjBx99NHp2bNn1ltvvfTv\n3z9XX311cwiefPLJWW+99T707fyv//W/Mm/evOy2227p379/Hn300bz44ovZZptt1vprAKD9ecYP\ngGZXXXVVdtpppzUGyp577pmamppcc801SZLJkyfn6KOPzumnn56tt946//Iv/5Lnn38+yT9e3nfH\nHXdk3333zTHHHJOtttoqhxxySIv3iF177bXp1atXRowYkYMOOihHHXVUNtpoow+c8Stf+UpOO+20\nnHrqqfnMZz6T//qv/8qPf/zjFsd85jOfybRp0/Lqq69m9913z3bbbZcLLrigxcsSkzT/uoSjjjqq\nVfu57rrrctVVV2XatGnZe++9s/XWW+fYY4/NgAEDctJJJyX5x/vbbr/99kyfPj2f/exnc+ihh+bL\nX/5y88tR19b++++f9ddfP7vuumsOOuigfOUrX8nEiROT/OOll7/85S8zd+7cDB06NIcffnhOOOGE\nVu31n/Xt2ze/+c1vss8++2TLLbfMySefnNNPPz1HHHFEm3wdALSvqiYvugfgY+ryyy/PhAkT8uKL\nL7b4oJWOauTIkRkyZEhzfANAa3mpJwAfO2+++Wbmz5+f888/P8cee+x/i+gDgLXhpZ4AfOx8+9vf\nztChQ7Pttts2v0QTAErmpZ4AAACF84wfAABA4YQfAABA4YQfAABA4drlUz0vv/zyzJo1K3369MkF\nF1yw2uVNTU2ZPHlyHnvssXTr1i3jx4//wF+k+46XX365rcctSr9+/Vr83izahr1Wjt1Whr1Wjt1W\nhr1Wjt1Whr1Whr1+sEGDBrXquHZ5xm/kyJE59dRT3/Pyxx57LK+88kouvvjiHHXUUX4/EQAAQBtq\nl/DbZptt0qtXr/e8fObMmdltt91SVVWVLbfcMm+99VZee+219hgNAACgeB3iPX719fXp169f8+na\n2trU19evw4kAAADK0S7v8WtLU6dOzdSpU5MkEydObBGMrK66utqOKsBeK8duK8NeK8duK8NeK8du\nK8NeK8Ne206HCL+ampoWb9pcvHhxampq1njs6NGjM3r06ObT3uz5/rwhtjLstXLstjLstXLstjLs\ntXLstjLstTLs9YN1qA93+SDDhw/P9OnT09TUlGeffTY9evRI37591/VYAAAARWiXZ/wuuuiiPPPM\nM3njjTdyzDHH5MADD0xDQ0OSZK+99sr222+fWbNm5Tvf+U66du2a8ePHt8dYAAAAHwvtEn4nnHDC\n+15eVVWVI488sj1GAQAA+NjpEC/1BAAAoHKEHwAAQOGEHwAAQOGEHwAAQOGEHwAAQOGEHwAAQOGE\nHwAAQOGEHwAAQOGEHwAAQOGEHwAAQOGEHwAAQOGEHwAAQOGEHwAAQOGEHwAAQOGEHwAAQOGEHwAA\nQOGq1/UAAEDH0Hj7Tet6hGZv9uiRxqVL1/UYSZJOY76+rkcAWGue8QMAACic8AMAACic8AMAACic\n8AMAACicD3epAG+OX503xnds7rOrc58F4OOso/xs0FF+Lkj++/9s4Bk/AACAwgk/AACAwgk/AACA\nwgk/AACAwgk/AACAwvlUT/5b8QlTq/vv/glTAABUnmf8AAAACif8AAAACif8AAAACif8AAAACif8\nAAAACif8AAAACif8AAAACif8AAAACif8AAAACif8AAAACif8AAAACif8AAAACif8AAAACif8AAAA\nCif8AAAACif8AAAACif8AAAACif8AAAACif8AAAACif8AAAACle9rgcAgA+r8fab1vUIzd7s0SON\nS5eu6zHSaczX1/UI0O48FqyZxwPWxDN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAA\nhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+\nAAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAA\nhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+\nAAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAA\nhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhRN+AAAAhaturxuaPXt2Jk+enMbGxowaNSr77bdfi8sX\nLVqUyy67LG+99VYaGxvz9a9/PcOGDWuv8QAAAIrVLuHX2NiYSZMm5fTTT09tbW1OOeWUDB8+PJts\nsknzMb/+9a+zyy67ZK+99sr8+fNz3nnnCT8AAIA20C4v9ZwzZ04GDhyYAQMGpLq6OiNGjMgjjzzS\n4piqqqosXbo0SbJ06dL07du3PUYDAAAoXrs841dfX5/a2trm07W1tXnuuedaHHPAAQfk7LPPzu9+\n97ssX748Z5xxRnuMBgAAULx2e4/fB3nggQcycuTIfPWrX82zzz6bSy65JBdccEE6dWr5pOTUqVMz\nderUJMnEiRPTr1+/dTHu+3qzR491PUKzTp06pUcHmKdXG32fOspuO8pek7bZbUfZa9JxdttW99mO\norq6ukM+Xn5U7rOr81hQOR4POi732TUr6fGgtL2uS+0SfjU1NVm8eHHz6cWLF6empqbFMffdd19O\nPfXUJMmWW26ZlStX5o033kifPn1aHDd69OiMHj26+fSiRYsqOPlH0/j/vWS1I+jRo0fzS2jXpWVt\n9H3qKLvtKHtN2ma3HWWvScfZbVvdZzuKfv36dcjHy4/KfXZ1Hgsqx+NBx+U+u2YlPR6UttdKGDRo\nUKuOa5f3+NXV1WXBggVZuHBhGhoaMmPGjAwfPrzFMf369ctTTz2VJJk/f35WrlyZ3r17t8d4AAAA\nRWuXZ/w6d+6ccePG5ZxzzkljY2P22GOPbLrpppkyZUrq6uoyfPjwfOMb38jPfvaz3HHHHUmS8ePH\np6qqqj3GAwAAKFq7vcdv2LBhq/16hrFjxzb/+yabbJIf/ehH7TUOAADAx0a7vNQTAACAdUf4AQAA\nFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74\nAQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAA\nFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74\nAQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAA\nFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74\nAQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAA\nFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74\nAQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAA\nFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74\nAQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAAFE74AQAA\nFE74AQAAFE74AQAAFK66vW5o9uzZmTx5chobGzNq1Kjst99+qx0zY8aM/PKXv0xVVVUGDx6c448/\nvr3GAwAAKFa7hF9jY2MmTZqU008/PbW1tTnllFMyfPjwbLLJJs3HLFiwILfddlt+9KMfpVevXlmy\nZEl7jAYAAFC8dnmp55w5czJw4MAMGDAg1dXVGTFiRB555JEWx9x7773Ze++906tXryRJnz592mM0\nAACA4rXLM3719fWpra1tPl1bW5vnnnuuxTEvv/xykuSMM85IY2NjDjjggGy33XbtMR4AAEDR2u09\nfh+ksbExCxYsyJlnnpn6+vqceeaZ+clPfpKePXu2OG7q1KmZOnVqkmTixInp16/fuhj3fb3Zo8e6\nHqFZp06d0qMDzNOrjb5PHWW3HWWvSdvstqPsNek4u22r+2xHUV1d3SEfLz8q99nVeSyoHI8HHZf7\n7JqV9HhQ2l7XpXYJv5qamixevLj59OLFi1NTU7PaMVtssUWqq6uz4YYbZqONNsqCBQsyZMiQFseN\nHj06o0ePbj69aNGiyg7/ETQuXbquR2jWo0ePLO0A8yxro+9TR9ltR9lr0ja77Sh7TTrObtvqPttR\n9OvXr0M+Xn5U7rOr81hQOR4POi732TUr6fGgtL1WwqBBg1p1XLu8x6+uri4LFizIwoUL09DQkBkz\nZmT48OEtjtlxxx3z9NNPJ0lef/31LFiwIAMGDGiP8QAAAIrWLs/4de7cOePGjcs555yTxsbG7LHH\nHtl0000zZcqU1NXVZfjw4fnsZz+bxx9/PN/97nfTqVOnHHLIIVl//fXbYzwAAICitdt7/IYNG5Zh\nw4a1OG/s2LHN/15VVZXDDjsshx12WHuNBAAA8LHQLi/1BAAAYN3pMJ/qCVCixttvWtcjJPnHp7N1\nlDfqdxrz9XU9ArS7jvJYkHScxwOPBdC+POMHAABQOOEHAABQOOEHAABQOOEHAABQOOEHAABQOOEH\nAABQOOEHAABQOOEHAABQOOEHAABQOOEHAABQOOEHAABQOOEHAABQOOEHAABQOOEHAABQOOEHAABQ\nOOEHAABQOOEHAABQOOEHAABQOOEHAABQOOEHAABQOOEHAABQOOEHAABQOOEHAABQuFaFX2NjY556\n6qk0NDRUeh4AAADaWKvCr1OnTjn//PNTXV1d6XkAAABoY61+qefWW2+dZ599tpKzAAAAUAGtfgqv\nf//+Oe+88zJ8+PDU1tamqqqq+bKxY8dWZDgAAADWXqvDb8WKFfnc5z6XJKmvr6/YQAAAALStVoff\n+PHjKzkHAAAAFfKhPq3lpZdeyoMPPpglS5bkiCOOyMsvv5yVK1dm8ODBlZoPAACAtdTqD3d58MEH\n88Mf/jD19fWZPn16kuTtt9/OL37xi4oNBwAAwNpr9TN+N998c84444xsttlmefDBB5MkgwcPzgsv\nvFCp2QAAAGgDrX7Gb8mSJau9pLOqqqrFp3sCAADQ8bQ6/DbffPPml3i+44EHHsiQIUPafCgAAADa\nTqtf6vnNb34zZ599du67774sX74855xzTl5++eWcfvrplZwPAACAtdTq8Nt4441z0UUX5dFHH80O\nO+yQ2tra7LDDDunevXsl5wMAAGAtfahf59CtW7d86lOfSn19fWpqakQfAADAfwOtDr9Fixbl4osv\nznPPPZeePXvmrbfeyhZbbJHjjjsu/fv3r+SMAAAArIVWf7jLZZddls033zyTJ0/ONddck8mTJ2fz\nzTfPZZddVsn5AAAAWEutDr958+blkEMOaX55Z/fu3XPIIYdk3rx5FRsOAACAtdfq8Ntiiy0yZ86c\nFufNnTs3W265ZZsPBQAAQNt53/f4TZkypfnfBwwYkPPOOy/Dhg1LbW1tFi9enMceeyy77rprxYcE\nAADgo3vf8Fu8eHGL0zvttFOS5PXXX0+XLl2y4447ZsWKFZWbDgAAgLX2vuE3fvz49poDAACACvlQ\nv8dv+fLleeWVV7Js2bIW52+11VZtOhQAAABtp9Xh94c//CHXXnttqqur07Vr1xaXXXHFFW0+GAAA\nAG2j1eF3ww035MQTT8zQoUMrOQ8AAABtrNW/zqG6ujrbbLNNJWcBAACgAlodfmPHjs0vfvGLvP76\n65WcBwAAgDbW6pd6Dho0KDfffHPuuuuu1S579+/7AwAAoGNpdfhdcskl2W233TJixIjVPtwFAACA\njqvV4ffmm29m7NixqaqqquQ8AAAAtLFWv8dv5MiRmT59eiVnAQAAoAJa/YzfnDlz8rvf/S633HJL\nNthggxaXTZgwoc0HAwAAoG20OvxGjRqVUaNGVXIWAAAAKqDV4Tdy5MgKjgEAAECltDr87rvvvve8\nbM8992yTYQAAAGh7rQ6/+++/v8Xpv//973nllVfyqU99SvgBAAB0YK0OvzPPPHO18+6777689NJL\nbToQAAAAbavVv85hTUaOHPm+LwEFAABg3Wv1M36NjY0tTq9YsSLTp09Pz54923woAAAA2k6rw+9r\nX/vaaufV1NTk6KOPbtOBAAAAaFutDr9LL720xelu3bqld+/ebT4QAAAAbesDw2/ChAnve3lVVVV+\n+MMfttlAAAAAtK0PDL8vfOELazy/vr4+d955Z5YvX97mQwEAANB2PjD8/vl39L3xxhu59dZbc++9\n92bEiBHZf//9KzYcAAAAa6/V7/FbunRpbr/99tx1110ZNmxY/uM//iMDBw6s5GwAAAC0gQ8MvxUr\nVuSOO+7Ib3/722yzzTb593//92y66abtMRsAAABt4APD79hjj01jY2PGjBmTurq6LFmyJEuWLGlx\nzKc//emKDQgAAMDa+cDw69q1a5Lk7rvvXuPlVVVVq/2qBwAAADqODwy/yy67rD3mAAAAoEI6resB\nAAAAqCzhBwAAUDjhBwAAUDjhBwAAUDjhBwAAUDjhBwAAUDjhBwAAUDjhBwAAUDjhBwAAUDjhBwAA\nUDjhBwAAUDjhBwAAUDjhBwAAUDjhBwAAUDjhBwAAUDjhBwAAUDjhBwAAUDjhBwAAUDjhBwAAUDjh\nBwAAUDjhBwAAUDjhBwAAUDjhBwAAUDjhBwAAUDjhBwAAUDjhBwAAULh2C7/Zs2fn+OOPz3HHHZfb\nbrvtPY/705/+lAMPPDBz585tr9EAAACK1i7h19jYmEmTJuXUU0/NhRdemAceeCDz589f7bi33347\nd955Z7bYYov2GAsAAOBjoV3Cb86cORk4cGAGDBiQ6urqjBgxIo888shqx02ZMiX/43/8j3Tp0qU9\nxgIAAPhYaJfwq6+vT21tbfPp2tra1NfXtzhm3rx5WbRoUYYNG9YeIwEAAHxsVK/rAZJ/vBT0F7/4\nRcaPH/+Bx06dOjVTp05NkkycODH9+vWr9Hgf2ps9eqzrEZp16tQpPTrAPL3a6PvUUXbbUfaatM1u\nO8pek46zW/fZynGfrQx7rRy7rQx7rZySdlvaXteldgm/mpqaLF68uPn04sWLU1NT03x62bJlefHF\nFzNhwoQkyd///vecf/75Ofnkk1NXV9fiukaPHp3Ro0c3n160aFGFp//wGpcuXdcjNOvRo0eWdoB5\nlrXR96mj7Laj7DVpm912lL0gQTR2AAAgAElEQVQmHWe37rOV4z5bGfZaOXZbGfZaOSXttrS9VsKg\nQYNadVy7hF9dXV0WLFiQhQsXpqamJjNmzMh3vvOd5st79OiRSZMmNZ8+66yzcuihh64WfQAAAHx4\n7RJ+nTt3zrhx43LOOeeksbExe+yxRzbddNNMmTIldXV1GT58eHuMAQAA8LHUbu/xGzZs2Gof3DJ2\n7Ng1HnvWWWe1w0QAAAAfD+32C9wBAABYN4QfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQf\nAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA\n4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQf\nAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA\n4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQf\nAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA\n4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQf\nAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA\n4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQf\nAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA\n4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4YQfAABA4arb64Zmz56dyZMnp7Gx\nMaNGjcp+++3X4vLf/va3uffee9O5c+f07t073/rWt9K/f//2Gg8AAKBY7fKMX2NjYyZNmpRTTz01\nF154YR544IHMnz+/xTGbbbZZJk6cmJ/85CfZeeedc8MNN7THaAAAAMVrl/CbM2dOBg4cmAEDBqS6\nujojRozII4880uKYT3/60+nWrVuSZIsttkh9fX17jAYAAFC8dgm/+vr61NbWNp+ura1937C77777\nst1227XHaAAAAMVrt/f4tdb06dMzb968nHXWWWu8fOrUqZk6dWqSZOLEienXr187Ttc6b/bosa5H\naNapU6f06ADz9Gqj71NH2W1H2WvSNrvtKHtNOs5u3Wcrx322Muy1cuy2Muy1ckrabWl7XZfaJfxq\namqyePHi5tOLFy9OTU3Nasc98cQTufXWW3PWWWelS5cua7yu0aNHZ/To0c2nFy1a1PYDr6XGpUvX\n9QjNevTokaUdYJ5lbfR96ii77Sh7Tdpmtx1lr0nH2a37bOW4z1aGvVaO3VaGvVZOSbstba+VMGjQ\noFYd1y4v9ayrq8uCBQuycOHCNDQ0ZMaMGRk+fHiLY55//vlcffXVOfnkk9OnT5/2GAsAAOBjoV2e\n8evcuXPGjRuXc845J42Njdljjz2y6aabZsqUKamrq8vw4cNzww03ZNmyZfnpT3+aJOnXr1++//3v\nt8d4AAAARWu39/gNGzYsw4YNa3He2LFjm//9jDPOaK9RAAAAPlba5aWeAAAArDvCDwAAoHDCDwAA\noHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDC\nDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAA\noHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDC\nDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAA\noHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDC\nDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAA\noHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDC\nDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAA\noHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDC\nDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAAoHDCDwAA\noHDCDwAAoHDV7XVDs2fPzuTJk9PY2JhRo0Zlv/32a3H5ypUrc+mll2bevHlZf/31c8IJJ2TDDTds\nr/EAAACK1S7P+DU2NmbSpEk59dRTc+GFF+aBBx7I/PnzWxxz3333pWfPnrnkkkvy5S9/OTfeeGN7\njAYAAFC8dgm/OXPmZODAgRkwYECqq6szYsSIPPLIIy2OmTlzZkaOHJkk2XnnnfPUU0+lqampPcYD\nAAAoWruEX319fWpra5tP19bWpr6+/j2P6dy5c3r06JE33nijPcYDAAAoWru9x6+tTJ06NVOnTk2S\nTJw4MYMGDVrHE63BMf/Pup6ghZp1PUBb6kC7tdfKsdvKsNfKKWa39lo5dlsZ9lo5HWi3Re11HWqX\nZ/xqamqyePHi5tOLFy9OTU3Nex6zatWqLF26NOuvv/5q1zV69OhMnDgxEydOrOzQhfjBD36wrkco\nkr1Wjt1Whr1Wjt1Whr1Wjt1Whr1Whr22nXYJv7q6uixYsCALFy5MQ0NDZsyYkeHDh7c4Zocddsi0\nadOSJH/605+y7bbbpqqqqj3GAwAAKFq7vNSzc+fOGTduXM4555w0NjZmjz32yKabbpopU6akrq4u\nw4cPz5577plLL700xx13XHr16pUTTjihPUYDAAAoXru9x2/YsGEZNmxYi/PGjh3b/O9du3bN9773\nvfYa52Nj9OjR63qEItlr5dhtZdhr5dhtZdhr5dhtZdhrZdhr26lq8jsTAAAAitYu7/EDAABg3el8\n1llnnbWuh+jIDj300PzP//k/1+o66uvrc/nll2fEiBFrvPytt97K73//+wwZMqRVx/+zyy67LNdd\nd12mTZuWe+65JxtttFEGDBiwVjO3pbvvvjvz58/PZptttq5H+UDv/n7PmjUrEydOzPDhw3PHHXfk\nvPPOy6hRo9K9e/fVjj3wwAPz9ttv57Of/WyS5Pbbb8/jjz+ebbfddt18IRWwpv8W1sX39tFHH81F\nF12Uu+++O3feeWc6d+6c5cuX56KLLsqoUaOaj1u1alWOPvro7LrrrllvvfVy++2354orrsi9996b\n3//+9+nSpUu7zP33v/89P/vZz3LDDTfkD3/4Q6ZNm5b1118/G2+8cUVvd+7cubntttuy/fbbr/V1\ndbSdjx07Ng8//HB+97vfZerUqVm+fHm22GKLj/SBYFOmTEljY+N7Pma2xX38r3/9a84+++zcc889\n+c///M/cc889mTZtWh566KHsvvvuH/l629I7O73rrrvy2GOPZfvtt0/Xrl3X+noXLlyYH/7wh9l7\n773bYMr/380335yLL74406dPzz333JNXX301Q4cObdPbeMcLL7yQefPmZaONNqrI9b+z+3vuuSf3\n3ntvPvGJT6Rfv34Vua0P8u7v19NPP51rr702u+66a2bOnJmHH344n/rUp3LzzTe/79+H7f31HHjg\ngVmwYEF22mmnJP94HPq3f/u3/PnPf86uu+76vn/2nbkXLlyYxx57LJ/4xCeStO3j53t5907fy7Rp\n03Lvvfdm2LBhq+394Ycfzne/+92MGDEivXv3XuPe11tvvff9+fKiiy7Kr371q6xYsSKPPfbY+z4W\ntmYn777P/PP53/72t/PJT36y+dewTZw4MX379s2GG274ofb2Yb3Xz/Ef5ee2p59+Oq+99lqb35/f\n/X2utP92v8fvv6OampqceOKJ73n5W2+9lbvvvrv5L8YPOn5NDj300Oy888556qmnctVVV+Xiiy9e\nq5mTfzx4du7cea2vZ6+99lrr62hvTz75ZCZPnpzTTjst/fv3T5Ksv/76+c1vfpNDDjlkteO7dOmS\nhx56KPvtt1969+7d3uOuM5X+3jY1NaWpqSmdOv3jxQkNDQ256qqrcu6556a2tjYrV67Mq6++moED\nB6a+vj6vvvpq8/frySefzCabbJKamprcfffdefLJJ3PuueemR48eWbp0aR5++OGKzv7O/D/+8Y+z\n++675/jjj0+SvPrqq5k5c2bFb7uuri51dXVrfT0dceddu3bNj3/84yTJkiVLcvHFF+ftt9/OgQce\n+KGv693vNV+TtriPf+ITn2ie97LLLssOO+yQnXfeebXj2uox96N4904vvfTS3HXXXWv9Pz0r7ctf\n/nLGjBnzof9cY2Nj82NKa7zwwguZO3duxX4oe/fuZ8+enZtuuikTJkxo1Z/958fIShk+fHiLT2N/\nv78P1+br+Si6deuWF198MStWrEjXrl3zxBNPrPYrwz7Iq6++mj/+8Y/NwdJWj5/v55932hrv3vsD\nDzyQqqqqPPDAAznwwANX2/uNN96Yb3/72+/58+Xf//73zJ07N5dcckmrbnttd1JbW5tbb731Q3/N\nH+SjPm5+lJ/bnn766XTv3j1bbbXVh76997Jq1ao2u67WEH4fwcKFC3PFFVfkjTfeSO/evTN+/Pj0\n69cvr7zySi655JIsW7Ysn/vc53LHHXfk+uuvz8KFC/Mf//EfueCCC/Liiy/m8ssvT0NDQ5qamnLi\niSdmypQpeeWVV3LSSSdl6NCh2XvvvZuPb2xszA033JDHH388VVVVGTVqVL70pS+952xbbrll6uvr\nm0/Pmzcv1113XZYtW9Y8a9++fTNnzpxceeWVqaqqytChQzN79uxccMEFzf8XetmyZWlsbMyECRNy\n++2358EHH8zKlSuz44475sADD8yyZcty4YUXpr6+Po2NjfnXf/3XjBgxIjfeeGNmzpyZzp07Z+jQ\nofnGN76Rm2++Od27d8+YMWPywgsv5Oqrr87y5cszYMCAfOtb30qvXr1y1llnZciQIXn66aezdOnS\nHHPMMdl6663b49u5mmeeeSY/+9nPcsopp2TgwIHN5++xxx75wx/+kP322y+9evVq8Wc6deqU0aNH\n54477sjXvva19h55nXn39/a9voeNjY258cYb88wzz2TlypXZe++988UvfjHLli3L+eefn7feeisN\nDQ056KCD8rnPfS4LFy7MOeecky222CLz5s3LKaec0hwWy5Yty6pVq5p/x2eXLl2a/+/hLrvskgce\neCD77bdfkuSBBx7I5z//+STJrbfemrPOOis9evRIkvTo0SMjR46s+H6eeuqpVFdXt4iH/v37N/83\nvHDhwlx66aVZvnx5kmTcuHHZaqut8vTTT+c3v/lN8+8umjRpUurq6jJy5Mg1/jf24IMP5le/+lU6\ndeqUHj16ZMKECS2uY86cOZk8eXJWrlyZrl27Zvz48Rk0aFCmTZuWmTNnZvny5fnb3/6WHXfccbUf\n5Dr6zvv06ZOjjjoqp5xySg444IA0NTWt8f6WJLfddlvuv//+dOrUKdttt10OPvjgFiG2Lh6/nnji\nidxyyy3p3r17/va3v+XCCy/MtGnTctddd6WhoSFbbbVVxo0bl06dOuWxxx7Lr371qzQ0NGTgwIH5\n1re+le7du+f666/PrFmz0rlz52y33XZr/GH8w9hyyy3z17/+NUne97/T8847L1tttVWeffbZ1NTU\n5OSTT07Xrl0zb968XHHFFUnS4lm4FStW5JprrsncuXPTuXPnfOMb38inP/3pTJs2LQ8//HCWL1+e\nV155JV/96lfT0NCQ6dOnp0uXLjnllFNWe8x9L08++WSuv/76rFq1KnV1dfm3f/u3dOnSJccee2x2\n2WWXPPnkkxkzZkzq6uoyadKkvP766+nWrVuOPvrobLzxxqv9t3TGGWdkypQpWbFiRf7yl7/kX/7l\nX1r9apyP4u23307Pnj2bT6/p7981PUZ+73vfy7777ptZs2ala9euOemkk7LBBhu8588r//w/IA49\n9NBcf/317znXtGnTMnfu3BxxxBFJ3v/vw/f7eipl++23z6xZs7Lzzjs3Pw795S9/SdLy76kkOfHE\nE/P973+/xTNNN910U+bPn5+TTjopu+++ez75yU82P37efPPNWbRoURYuXJhFixZl3333zb777psk\n+e1vf5vf//73SZI999wzX/7yl7Nw4cKce+652WKLLfLss882P3b/8pe/zJIlS/Kd73wnQ4YMabHT\nmTNn5pZbbklDQ0PWX3/9HHfccdlggw1W+zrf2fs+++yTv/zlL6murm4Ov+QfYfLO/fWll17KTTfd\n9J4/X5599tmpr6/PSSedlHHjxuW+++5rvk/MmTMnP//5z7N8+fJUV1fnhz/8YebNm/eBf6e8n8GD\nB2fVqlV54oknVnt2/r1+Vj3rrLNy6KGHpq6uLq+//npOOeWUXHbZZav9rHrKKaes8XHq/bzfz22v\nv/56rrrqqubfL37YYYelpqYm99xzTzp16pT7778/3/zmN3PZZZfl0ksvzdKlSzNu3LiceeaZ2Wab\nbXLmmWfmmGOOyfrrr5/LL788CxcuTLdu3XLUUUdl8ODBufnmm/O3v/0tCxcuTG1tbbbbbrvm2541\na1Z+/etf5/vf/35FnkgQfh/Btddem9133z0jR47Mfffdl2uvvTYnn3xyfv7zn+dLX/pSdt1119x9\n991r/LP33HNP9t1333zhC19IQ0NDGhsb8/Wvfz0vvvhi8/+pWbhwYfPxU6dOzauvvprzzz8/nTt3\nzptvvvm+s82ePbv5zt7Q0NA8W+/evTNjxoz853/+Z8aPH58rrrgiRx99dLbccsvceOONLa7j+eef\nz09+8pP06tUrjz/+eBYsWJBzzz03TU1NOf/88/PMM8/k9ddfT9++fXPKKackSZYuXZo33ngjDz/8\n/7Z37kFRVu8D/yy7LsKCpCJOiJSICIRIwmiGUeqkqJhmXlJnEhw1krwk4DWzr4rXRJwANa+NTuZE\npJRmXhNFTR1MQDFNQkVARBgxYAVhf3/s7BkWdrkolvk7n7/YfXnf97znfc5znuc5z3P2LDExMSgU\nCkpLS+u0LzY2lokTJ+Lp6cnu3btJSEggODgY0Edhly9fTmpqKgkJCSxcuLBxL6QZefToEatXr+bz\nzz+vk4rXsmVL+vbty/79+02uLAwcOJDIyEiGDRv2TzX3mcPUOzx69CjW1tYsX76cyspKFi5cSPfu\n3Wnbti0RERFYW1tTUlLCggULRCQwPz+fsLAw3NzcjK5vY2ODn58fU6dOxcvLC19fX/z9/bGwsMDf\n35+NGzcyfPhwKisruXDhAhMmTKCsrAytVvuvpD/funWLTp06mT1uZ2fHp59+ilqtJi8vj3Xr1rFi\nxQqz/29ujCUkJLBgwQLatGljctw5OjqyePFilEolaWlpfPPNN0RERAD61YxVq1ahUqmYOXMmgYGB\nRmks/4U+b9++PdXV1dy/f5/z58+blLfbt29z/vx5li1bhqWlZR1d+m/qr+vXr7N27Vrs7e25efMm\nZ8+eZenSpSiVSjZu3MipU6fo1q0be/bs4bPPPsPS0pLExET2799Pv379uHDhAtHR0Wbb3RSqq6vJ\nyMigX79+gN7RNzdO8/LymDFjBqGhoURHR3PmzBkCAgKIj48X/VTTmfjll18AWLNmDbdv32bp0qWs\nW7cO0I+VVatWUVlZybRp0xg/fjyrVq1i+/btHD9+nCFDhtRp6759+zhx4gQA48ePx9PTk/j4eBYu\nXIijoyOxsbEcPHhQnGtra8vKlSsBWLx4MZMnT+bFF1/k2rVrbN68mUWLFtUZSyqVijFjxhg5Pc1N\nRUUFkZGRVFZWUlxczKJFiwDMzr+GQHNNHWlIdx47diw7d+7kyJEjvPfee2btlSelvvnQ3PM8Tfz9\n/UlISKBHjx7cuHGDvn37CsevMYwbN84o2Hbp0iWj47m5uSxatIjy8nJmzpzJgAEDuHnzJseOHSMq\nKgqA+fPn4+npiUajIT8/n1mzZuHk5MS8efM4efIkixcvFg5e7Xfg7u5OVFQUCoWCI0eOkJSUxAcf\nfFCnnYZ+3759Oz4+Ppw6dQpbW1uysrKoqKhgw4YNFBQUoFar+d///oeNjY1Z+3L27NmsXLlSHDt6\n9Cigt4NiYmKYOXMmrq6ulJWV1Un7rm9OqY93332X3bt3Gzl+9dmq9VHTVq2qqjKppxpK/zdnt23b\nto2goCDc3d0pLCwkKiqKtWvX8vbbbxsFERwdHcnJyaGgoAAXFxeuXLlCly5dKCws5MUXX2Tr1q10\n6tSJ2bNnk5GRQWxsrOjvnJwclixZglqtFr9jfvbsWX766acmBbuainT8HoNr164JAQ8ICBCO09Wr\nV4mMjASgT58+JqNnbm5uJCYmcu/ePXr16tVgzUBaWhoDBgwQy9jmBGHHjh3s2rWLe/fusXTpUkCv\nqG7dusWSJUsA/YTeunVrSktLKS8vFxNGnz59SE1NFdfy9vYW97l48SJpaWlCSWm1WvLz83F3d2fH\njh3s3LkTX19fPDw8qKqqQq1Ws379enx9ffH19TVqY1lZGaWlpXh6egLw5ptvsnbtWnG8Z8+eALi4\nuBgpp38SpVJJ165dOXr0KCEhIXWODxo0iNmzZzN06NA6x6ytrQkICGD//v3NUhvzX8TUO7x48SI3\nb97kzJkzgF4O8vLyaNOmDbt27SIzMxOFQkFRURH3798HwN7evo7TZyA0NJSbN2+SlpbGjz/+SFpa\nGmFhYXTu3BmtVktubi45OTm4urpiY2NDWVnZP/DkjWPz5s388ccfqFQqli9fTlVVFVu2bCE7OxsL\nCwvy8vLqPd/a2trkGOvatStxcXH07t1b1LnUpKysjLi4OPLz8wHj1BIvLy+xKufk5ERhYWGd+oX/\nUp+bk7f09HTeeustLC0tgbq61FzfGnia+svNzU30eXp6OtevXxcGaEVFBW3btkWtVpOTk8Onn34K\n6I0ld3d3bGxsUCgUbNy40eTPJjUWg7FeVFSEk5OTMMx0Op3Zcerg4CBqH11cXLh79y6lpaVG/RQQ\nEMDvv/8OwJUrV8Rqd4cOHWjXrp2Q+VdeeQUrKyusrKywtrYWzqWzs7NYfaxN7VTP7OxsHBwcxMrD\nm2++yS+//CIcP8NKnVar5Y8//iA6Olqc++jRI6DhsfQ0qJmid/XqVWJjY1mzZo3Z+dfe3r6OjlSp\nVEJmXVxcSEtLA8zbK82BufnQ3PM8Tg1uY3nppZe4e/cuKSkpT6Uur0ePHrRo0YIWLVpgZ2fH/fv3\nuXLlCj179hR1jj179iQzMxM/Pz8cHBxEvWDHjh3p1q0bCoUCZ2dn7t69W+f6RUVFxMTEUFxczKNH\nj+qtexs0aBAffvghM2bM4NSpU7z++uucPHkStVpNaGgoCQkJjB07ltjYWObMmdPkZ83NzaV169ai\nLtAwP9SkvjmlPgx6oaZTbs5WbYiatqo5PWVq1bQm5uy29PR0cnJyjJ5Xq9XWOd/Dw4PMzEwKCgoY\nPnw4R44cwdPTU6TEXrlyRaTWenl58ffff4v50c/Pz+ieGRkZZGVlsWDBApN93lxIx+8fpk+fPri6\nupKamsry5cuZMmVKsxS2Gmr8fv75Z9avXy+imk5OTiIaZaChiLDBMDIwfPhwkSpVk5UrV5Kamsq3\n335Lt27dGDlyJMuWLSM9PZ0zZ85w4MCBJkX6WrRoAeiX36urqxt9XnOiUCj45JNPWLx4MYmJiXVq\nXDQaDf7+/iJyXZshQ4YwZ86cfySN8FnE1DvU6XSEhIQYpTKAPnWopKSEFStWoFKpCAsLo6KiAkBM\npOZwdnbG2dmZgIAAPv74Y8LCwgB91DclJYXbt2+LWg1ra2uRRvdPr/p17NiR3377TXyeNGmSSFcB\nfZqQnZ0dq1evRqfTMX78eEAfgKj5SzuVlZXie1NjbMqUKVy7do3U1FTmzp1bZ9Vw9+7dvPLKK0RG\nRlJQUGBUb2N4Z6B/b+Ym8Ge5z+/cuYOFhQV2dnZm5e3ixYv1XsNc3zaWJ9FfNXWuTqejb9++vP/+\n+0b/c/bsWXx8fJg2bVqd81esWEFaWhqnT5/m4MGDwjlsCgZj/eHDh0RFRXHgwAEGDx7MyZMnzY7T\n2rJj+P5xqH0tlUol/m6uGhhDP1dXV6PRaIRzUpOGxtLTxs3NjQcPHlBSUgKYnn8LCgrq6EilUikc\nq8b0mVKpFHJaXV0tHN+m0NB8WPt57OzsmnyPpuDn58eOHTv4/PPPefDggfi+tj59HDk1yCM0rn9r\nyrNCoRCfFQqFSf2wdetWgoKC8PPz49KlS3z33Xdmr63T6aiqqiIuLo6HDx/y448/iu9BL+eGfm8o\nS+xxqW9OaYgRI0bw/fffG9XlmbJVwfjdGeZBAzX1Zn16qiFM2W06nY6oqKgGg/geHh4cPHiQ4uJi\nRo8eTVJSEpcuXWpUqn9tW7t9+/YUFBSQl5f3VOtL5c85PAZubm6cOnUK0AubYUemLl26CCPPcLw2\nBkNo8ODB+Pn5cePGDaysrCgvLzf5/97e3hw6dEgomYYGcWBgIDqdjt9//x1HR0dKSkq4evUqoI9o\n3rp1C41Gg5WVFdeuXT4WoTAAAAbfSURBVAP0dTnm6N69O8eOHRORDkMUpaioCLVaTUBAAO+88w5Z\nWVlotVrKysro0aMHwcHB3Lhxw+ha1tbW2NjYkJmZCUBycvK/VsdXH5aWliI1w5D6UJOgoCAOHTpk\nUnnb2NjQu3dvk+f9f8XHx4eDBw8KwyI3N1fIip2dHSqVioyMDJNR0NpotVqjFJzs7GxR/wd6J+TE\niRNkZGQYFZAPHz6cLVu2iEibVqvl+PHjzfWIZvHy8qKystIo9bvmZFRWVkbr1q2xsLAgOTlZyJS9\nvT05OTlUVlZSWlpKenq6aLepMZafn0+XLl0YM2YMrVq1EnUJNe9j2OzAkFLSWJ71Pi8pKWHTpk0E\nBgaiUCjMypu3tze//vqrqKesrUufFf3l7e3N6dOnheH/4MEDCgsLcXNz4/Lly9y5c0e0Ny8vj/Ly\ncsrLy/H19SU4OJi//vrrie5vaWlJSEgIP/30E1VVVU0epxqNBo1GIyL6hlRM0BtJhs+5ubkUFhY2\nWBfUFBwdHSkoKBCrEMnJyWKFoSbW1tY4ODhw+vRpQG/kZWdnA6bHUsuWLc3O0c3N7du3qa6uxtbW\n1uz82xTM2Svt2rUjKysL0O8u+bjOdX3zYe3nedr07duXkSNHipU2A+3atRPjIisry+SKfH12mDnc\n3d05d+4cDx8+RKvVcu7cucfWCTV1dEN68syZM/j7+6PRaGjRogXr16/HwcHByLk19Lu9vX2Tn8vR\n0ZHi4mL+/PNPQF+nWVs+nmRO6d69O6WlpULHmrNVwVhODVkcpngce8KAKbvN29ubAwcOiM8G/WBl\nZWW08ufq6srVq1dRKBSo1WpefvllDh8+LOTA3d1d6LxLly5ha2trdjWvXbt2hIeHExsbK57/aSBX\n/BqgoqKC0NBQ8TkoKIiJEycSHx9PUlKSKEIFCA4O5ssvvyQxMREfHx+TL/f06dMkJyejVCp54YUX\nGDFiBDY2NnTt2pXw8HB8fHyMtr3u378/eXl5REREoFKp6N+/P4GBgWbbq1AoGDFiBElJSfj4+BAe\nHs62bdsoKyujqqqKwYMH07FjR0JDQ9m4cSMKhQJPT0+zgmiojVmwYAGgX4mZNm0a+fn57Ny5E4VC\ngUqlYtKkSZSXl4saDZ1OZzI/PSwsTGyO4ODg0GAO97+FjY0N8+fPZ9GiRXWKa1u1akXPnj3Zt2+f\nyXODgoKMFMbzgqmx0Bj69etHQUGBSDlp1aoVkZGR9OnTh5UrVxIeHk7nzp0b9fMGOp2OpKQkvvrq\nK9RqNS1btjSSIScnJywtLXFxcTGKiA8YMACtVsu8efNQqVQolcpGt/9JUCgUREZG8vXXX7N3715a\ntWpFy5YtxcrewIEDWbNmDcnJyXTv3l1EAO3t7enduzfh4eE4ODiIOkFzY2znzp0iZc7Ly4uXXnqJ\ny5cvi3YMGzaMuLg4EhMTm5wK+Cz2uSEt0bCb2xtvvCGubU7efHx8yM7OZu7cuahUKl599VXGjRsn\nrvms6C9nZ2dGjRrFkiVL0Ol0KJVKJk+ejKurKx999BExMTHCqR07dixqtZovvvhC1IxPmDDhidvQ\nqVMnnJ2dSUlJeaxxaqgjB8RW6aCXic2bNxMeHo5SqWTq1KlGKyNPimGTiejoaLG5i6lsFYDp06ez\nadMmsaGGv78/L7/8ssmxZG9vz969e4mMjHwqm7sY5NlAWFgYFhYWZuffpuzgac5e6d+/P6tXryYy\nMtJI9zQVU/Ohued52rRt21ZsulKT1157jeTkZGbNmoWrq6vJYIOzszMWFhZGm7s0hIuLC2+99Rbz\n588H9LqnU6dOj1WqMmrUKKKjo9FoNHh5edV7jZSUFIYNG4atra3o9169epGZmcmGDRsoKSkhJiaG\nsLAw7OzszNqX5jDUe2/btk3slFq7ZvlJ5hTQr/qtWrVK3M+crTp06FDWrl3L4cOH673P4+ipmtS2\n20JCQtiyZQsRERFUVVXh4eHBlClT8PX1JTo6mnPnzjFx4kQ8PDxo27YtXbp0AfTBrZSUFBF8GD16\nNPHx8URERGBpaSkyZczRoUMHpk+fTnR0NHPmzDHaYLC5UOhqhggkT8TDhw9Rq9Vie92UlJRmKaJ+\nGmi1WmGk7dmzh+LiYpM1bRKJRCKRSCQSieS/j1zxa0aysrLYunUrOp0OjUbDRx999G83ySypqan8\n8MMPIhWgoSiERCKRSCQSiUQi+e8iV/wkEolEIpFIJBKJ5DlHbu4ikUgkEolEIpFIJM850vGTSCQS\niUQikUgkkucc6fhJJBKJRCKRSCQSyXOOdPwkEolEIpFIJBKJ5DlHOn4SiUQikUgkEolE8pwjHT+J\nRCKRSCQSiUQiec75Pz901o0EcGl7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80smu6PTvpiW",
        "colab_type": "text"
      },
      "source": [
        "## Saving Our Model and the Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5WZT1Uuvq_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Random Forest Model\n",
        "import pickle\n",
        "filename = 'Breast_Cancer.sav'\n",
        "pickle.dump(randomforest, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbV0u_MtSxOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.save(\"ANN_rest_Cancer.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj5YxEqnTAqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}